@article{MORADI2023108549,
title = {Spoken language identification using a genetic-based fusion approach to combine acoustic and universal phonetic results},
journal = {Computers and Electrical Engineering},
volume = {105},
pages = {108549},
year = {2023},
issn = {0045-7906},
doi = {https://doi.org/10.1016/j.compeleceng.2022.108549},
url = {https://www.sciencedirect.com/science/article/pii/S0045790622007649},
author = {Ashkan Moradi and Yasser Shekofteh},
keywords = {Spoken language identification, x-vectors, Acoustic-based approach, Phonetic-based approach, Universal phone recognition, Classifier fusion, Genetic algorithm},
abstract = {Identification of the spoken languages in an audio file is performed automatically using the spoken language identification (LID) process. In this paper, we proposed a genetic-based fusion method to combine the score probabilities of an x-vector-based acoustic LID (ALID) and a phonetic LID (PLID) system. The ALID system is based on an LDA classifier able to identify different languages using x-vectors, while the PLID system is based on an SVM classifier which takes into account perplexities as its feature vector, which are derived from phone language models utilizing a universal phone recognizer named Allosaurus. With the help of genetic-based fusion, 54 weights will be extracted. Having 27 languages in our database and two different LID systems results in 54 weights for our fusion. The individual results of our acoustic and phonetic LID systems are eventually combined by applying these weights. Based on the experimental results on 27 languages from the NIST-LRE09 database, the fusion of the acoustic system and the phonetic system results in 93.30% accuracy, which has approximately a 21% reduction in identification error to our best baseline system with 91.50% accuracy.}
}
@article{XUE2025100807,
title = {Application of entertainment interactive robot based on speech recognition in English artificial intelligence teaching evaluation and automatic feedback},
journal = {Entertainment Computing},
volume = {52},
pages = {100807},
year = {2025},
issn = {1875-9521},
doi = {https://doi.org/10.1016/j.entcom.2024.100807},
url = {https://www.sciencedirect.com/science/article/pii/S1875952124001757},
author = {Yuanyuan Xue},
keywords = {Deep reinforcement learning, Speech recognition algorithm, Entertainment interactive robots, System design},
abstract = {With the development of intelligent voice and interactive robot technology, new technologies have built a virtual E-learning learning environment that can provide students with an immersive learning experience, making this new learning mode more entertaining. This article investigates the application of entertainment interactive robots based on speech recognition in English artificial intelligence teaching evaluation and automatic feedback. The system has constructed an oral evaluation model based on deep reinforcement learning, which learns the optimal behavioral strategies through interaction with the environment. The model will train through oral conversations with learners to learn how to accurately evaluate oral proficiency and provide relevant feedback. After the construction of the system is completed, the accuracy and efficiency of the system are improved by adjusting the parameters of the model, increasing the diversity of training data, and improving the user interface and interaction mode based on user feedback, making it more friendly and easy to use. The experimental results show that the English oral evaluation and automatic feedback system designed in this paper based on deep reinforcement learning and speech recognition algorithms has high accuracy and efficiency. The system can accurately evaluate learners’ oral proficiency and provide personalized learning suggestions based on individual differences.}
}
@article{SINGH2025100128,
title = {A survey on chatbots and large language models: Testing and evaluation techniques},
journal = {Natural Language Processing Journal},
volume = {10},
pages = {100128},
year = {2025},
issn = {2949-7191},
doi = {https://doi.org/10.1016/j.nlp.2025.100128},
url = {https://www.sciencedirect.com/science/article/pii/S2949719125000044},
author = {Sonali Uttam Singh and Akbar Siami Namin},
keywords = {Large Language Models (LLM), Chatbot, Conversational Chatbot, Intelligent Personal Assistant (IPA), ChatGPT, Natural Language Understanding (NLU), Natural Language Processing (NLP)},
abstract = {Chatbots have been quite developed in the recent decades and evolved along with the field of Artificial Intelligence (AI), enabling powerful capabilities in tasks such as text generation and summarization, sentiment analysis, and many other interesting Natural Language Processing (NLP) based tasks. Advancements in language models (LMs), specifically LLMs, have played an important role in improving the capabilities of chatbots. This survey paper provides a comprehensive overview in chatbot with the integration of LLMs, primarily focusing on the testing, evaluation and performance techniques and frameworks associated with it. The paper discusses the foundational concepts of chatbots and their evolution, highlights the challenges and opportunities they present by reviewing the state-of-the-art papers associated with the chatbots design, testing and evaluation. The survey also delves into the key components of chatbot systems, including Natural Language Understanding (NLU), dialogue management, and Natural Language Generation (NLG), and examine how LLMs have influenced each of these components. Furthermore, the survey examines the ethical considerations and limitations associated with LLMs. The paper primarily focuses on investigating the evaluation techniques and metrics used to assess the performance and effectiveness of these language models. This paper aims to provide an overview of chatbots and highlights the need for an appropriate framework in regards to testing and evaluating these chatbots and the LLMs associated with it in order to provide efficient and proper knowledge to user and potentially improve its quality based on advancements in the field of machine learning.}
}
@article{GAN202333,
title = {Design and user experience analysis of AR intelligent virtual agents on smartphones},
journal = {Cognitive Systems Research},
volume = {78},
pages = {33-47},
year = {2023},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2022.11.007},
url = {https://www.sciencedirect.com/science/article/pii/S1389041722000699},
author = {Quehong Gan and Zhen Liu and Tingting Liu and Yumeng Zhao and Yanjie Chai},
keywords = {Intelligent virtual agents, Augmented reality, Cognitive architecture, Emotional expression, Uncertainty, User experience},
abstract = {Intelligent Virtual Agents (IVAs) can provide users with a friendly experience and have a wide range of applications in the era of artificial intelligence. However, most of existing IVAs are designed for personal computers. Design and user studies of IVAs on smartphones are uncommon. Therefore, developing IVAs for smartphones is an interesting topic. Considering Augmented Reality (AR) technology can provide more potential application value for IVAs, we mainly investigate users’ experiences of AR IVAs on smartphones in this paper. To make an IVA more suitable for a smartphone, a lightweight IVA’s cognitive architecture is proposed. To find out the factors that affect users’ interaction experiences, the effects of humanoid embodiment and emotional expressions of IVAs on users’ perceptions and experiences are explored. A museum is used as a specific task scenario to measure users’ experiences. Three forms of AR agents are evaluated in this scenario: a voice assistant without an entity, a humanoid IVA without emotional expressions, and a humanoid IVA with emotional expressions. The results show that compared with the voice assistant, a humanoid embodiment can significantly improve the user’s experience, and compared with humanoid IVA without emotional expressions, a humanoid IVA with emotional expressions is more welcome. Moreover, we use the cloud model to describe the uncertainty of IVAs’ actions (blinking and body orientation). The results show that the uncertainty of actions can increase the believability of IVAs.}
}
@article{SONG2023144,
title = {Chinese Speech Recognition System Based on Neural Network Acoustic Network Model},
journal = {Procedia Computer Science},
volume = {228},
pages = {144-154},
year = {2023},
note = {3rd International Conference on Machine Learning and Big Data Analytics for IoT Security and Privacy},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2023.11.018},
url = {https://www.sciencedirect.com/science/article/pii/S1877050923018410},
author = {Yuhan Song},
keywords = {Neural network, Speech recognition, I-vector},
abstract = {In order to understand the Chinese speech recognition system based on network models, the author proposes a research on a Chinese speech recognition system based on neural network acoustic network models. The author first analyzed a speech recognition system based on neural networks. The system first performs sampling and filtering, pre weighting, signal framing, and endpoint detection operations on the speech signal, extracts the LPC, LPCC, and MFCC values of the preprocessed data, improves the MFCC values, and trains and constructs a neural network model, secondly, in view of the problem that the accuracy of System identification recognition declines when there is a large difference between the target Chinese speech tested and the speaker speech of training data in the speech recognition system, a speaker language adaptation SA (Speaker Adaptation) method based on deep neural network (DNN) is proposed. It is speaker adaptation in the feature space. By adding speaker identity vector information to the DNN Acoustic model, speaker difference information in the feature is removed to reduce the impact of speaker difference and retain semantic information. Finally, the experimental results on TEDLIUM open source dataset show that when the features of this method are fbank and fMLLR respectively, the system word error rate WER (Word Error Rate) is improved by 7.8% and 6.8% compared with the baseline neural network DNN Acoustic model. The reasonable selection of speech features can not only improve the training efficiency of the recognition model, but also effectively improve the recognition accuracy of the model, thereby improving recognition performance.}
}
@article{ZHANG2024109854,
title = {Artificial intelligence in sign language recognition: A comprehensive bibliometric and visual analysis},
journal = {Computers and Electrical Engineering},
volume = {120},
pages = {109854},
year = {2024},
issn = {0045-7906},
doi = {https://doi.org/10.1016/j.compeleceng.2024.109854},
url = {https://www.sciencedirect.com/science/article/pii/S004579062400781X},
author = {Yanqiong Zhang and Yu Han and Zhaosong Zhu and Xianwei Jiang and Yudong Zhang},
keywords = {Artificial intelligence, Sign language recognition, Deep learning, Bibliometrics, VOSviewer, CiteSpace},
abstract = {Sign language recognition (SLR) plays a crucial role in bridging the communication gap between individuals with hearing impairments and the auditory communities. This study explores the use of artificial intelligence (AI) in SLR through a comprehensive bibliometric analysis of 2,720 articles published from 1988 to 2024. Utilizing tools like VOSviewer and CiteSpace, the research uncovers the landscape of publication outputs, influential articles, leading authors, as well as the intellectual framework of current topics and emerging trends. The findings indicate that since the inception of SLR research in 1988, there has been a rapid expansion in the field, particularly from 2004 onwards. China and India lead in research productivity. Keyword and co-citation analyses highlight that Hidden Markov Model, Kinect, and Deep Learning have been focal points at various stages of SLR development, while transfer learning, Bidirectional Long Short-Term Memory, attention mechanisms, and Transformer models represent recent emerging trends. This research offers valuable insights for scholars and practitioners interested in AI-based SLR.}
}
@article{KAPSE2025935,
title = {MediServe: An IoT-Enhanced Deep Learning Framework for Personalized Medication Management for Elderly Care},
journal = {Computers, Materials and Continua},
volume = {83},
number = {1},
pages = {935-976},
year = {2025},
issn = {1546-2218},
doi = {https://doi.org/10.32604/cmc.2025.061981},
url = {https://www.sciencedirect.com/science/article/pii/S1546221825002693},
author = {Smita Kapse and Ganesh Yenurkar and Vincent Omollo Nyangaresi and Gunjan Balpande and Shravani Kale and Manthan Jadhav and Sahil Lawankar and Vikrant Jaunjale},
keywords = {MediServe, medication, health risks, smart medication box},
abstract = {In today’s fast-paced world, many elderly individuals struggle to adhere to their medication schedules, especially those with memory-related conditions like Alzheimer’s disease, leading to serious health risks, hospitalizations, and increased healthcare costs. Traditional reminder systems often fail due to a lack of personalization and real-time intervention. To address this critical challenge, we introduce MediServe, an advanced IoT-enabled medication management system that seamlessly integrates deep learning techniques to provide a personalized, secure, and adaptive solution. MediServe features a smart medication box equipped with biometric authentication, such as fingerprint recognition, ensuring authorized access to prescribed medication while preventing misuse. A user-friendly mobile application complements the system, offering real-time notifications, adherence tracking, and emergency alerts for caregivers and healthcare providers. The system employs predictive deep learning models, achieving an impressive classification accuracy of 98%, to analyze user behavior, detect anomalies in medication adherence, and optimize scheduling based on an individual’s habits and health conditions. Furthermore, MediServe enhances accessibility by employing natural language processing (NLP) models for voice-activated interactions and text-to-speech capabilities, making it especially beneficial for visually impaired users and those with cognitive impairments. Cloud-based data analytics and wireless connectivity facilitate remote monitoring, ensuring that caregivers receive instant alerts in case of missed doses or medication mismanagement. Additionally, machine learning-based clustering and anomaly detection refine medication reminders by adapting to users’ changing health patterns. By combining IoT, deep learning, and advanced security protocols, MediServe delivers a comprehensive, intelligent, and inclusive solution for medication adherence. This innovative approach not only improves the quality of life for elderly individuals but also reduces the burden on caregivers and healthcare systems, ultimately fostering independent and efficient health management.}
}
@article{BAHA2022397,
title = {Towards highly adaptive Edu-Chatbot},
journal = {Procedia Computer Science},
volume = {198},
pages = {397-403},
year = {2022},
note = {12th International Conference on Emerging Ubiquitous Systems and Pervasive Networks / 11th International Conference on Current and Future Trends of Information and Communication Technologies in Healthcare},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2021.12.260},
url = {https://www.sciencedirect.com/science/article/pii/S1877050921024996},
author = {Tarek AIT BAHA and Mohamed EL HAJJI and Youssef ES-SAADY and Hammou FADILI},
keywords = {Chatbot, Machine Learning, NLP, Transformers, Education},
abstract = {Conversational Agents are widely used in different domains to automate tasks and help to improve user experience. In recent decades, AI systems, thanks to deep learning methods and Natural Language Processing (NLP) approaches, can interact with users, understand their needs, map their preferences and recommend an appropriate action with no human intervention. However, chatbots in the education field have received limited attention. In this work, we use Xatkit, a chatbot development framework, for the definition of our Chatbot and propose an Encoder-Decoder framework for intent recognition. For the encoder, we encode utterances as context representations using bidirectional transformer (CamemBERT). For the decoder, we use an intent classification decoder to detect the student’s intent. Our chatbot will be tested in the field of education to improve and simplify teaching for professors and learning for students as well as reducing faculty burnout and raising the speed of comprehension.}
}
@article{BARRAVECCHIA20243141,
title = {Advancing Human-Robot Collaboration: proposal of a methodology for the design of Symbiotic Assembly Workstations},
journal = {Procedia Computer Science},
volume = {232},
pages = {3141-3150},
year = {2024},
note = {5th International Conference on Industry 4.0 and Smart Manufacturing (ISM 2023)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.02.130},
url = {https://www.sciencedirect.com/science/article/pii/S1877050924003089},
author = {Federico Barravecchia and Mirco Bartolomei and Luca Mastrogiacomo and Fiorenzo Franceschini},
keywords = {Collaborative robot, Symbiotic Human-Robot Collaboration, Assembly workstation, Design methodology},
abstract = {The rapid advancement of robotics and artificial intelligence paves the way for collaborative robotics to revolutionise industrial operations. Collaborative robotics can bring significant improvements in productivity, efficiency, and safety. Recently, the concept of Symbiotic Human-Robot Collaboration (SHRC) has emerged within the field of collaborative robotics, emphasising the seamless and adaptive integration of human and robotic capabilities within a shared workspace to optimise overall production performance. However, existing collaborative systems frequently face difficulties in establishing dynamic relationships with humans and adapting to evolving conditions, ultimately restricting their overall potential. This paper investigates the essential features required for collaborative workstations to enable SHRC. Moreover, with the aim of fully harnessing the power of collaborative robotics, the paper introduces a design methodology that supports the development of symbiotic workstations for specific assembly operations. A real-world case study is provided, demonstrating the practical implementation and benefits of the proposed design approach.}
}
@article{TATAR2024105101,
title = {Recent advances in Machine Learning based Advanced Driver Assistance System applications},
journal = {Microprocessors and Microsystems},
volume = {110},
pages = {105101},
year = {2024},
issn = {0141-9331},
doi = {https://doi.org/10.1016/j.micpro.2024.105101},
url = {https://www.sciencedirect.com/science/article/pii/S0141933124000966},
author = {Guner Tatar and Salih Bayar and Ihsan Cicek and Smail Niar},
keywords = {Artificial Intelligence, Machine and deep learning, Advanced/Driver Assistance Systems, Automotive Safety Integrity Level, FPGAs, GPUs, ASICs and CPUs},
abstract = {In recent years, the rise of traffic in modern cities has demanded novel technology to support the drivers and protect the passengers and other third parties involved in transportation. Thanks to rapid technological progress and innovations, many Advanced Driver Assistance Systems (A/DAS) based on Machine Learning (ML) algorithms have emerged to address the increasing demand for practical A/DAS applications. Fast and accurate execution of A/DAS algorithms is essential for preventing loss of life and property. High-speed hardware accelerators are vital for processing the high volume of data captured by increasingly sophisticated sensors and complex mathematical models’ execution of modern deep learning (DL) algorithms. One of the fundamental challenges in this new era is to design energy-efficient and portable ML-enabled platforms for vehicles to provide driver assistance and safety. This article presents recent progress in ML-driven A/DAS technology to offer new insights for researchers. We covered standard ML models and optimization approaches based on widely accepted open-source frameworks extensively used in A/DAS applications. We have also highlighted related articles on ML and its sub-branches, neural networks (NNs), and DL. We have also reported the implementation issues, bench-marking problems, and potential challenges for future research. Popular embedded hardware platforms such as Field Programmable Gate Arrays (FPGAs), central processing units (CPUs), Graphical Processing Units (GPUs), and Application Specific Integrated Circuits (ASICs) used to implement A/DAS applications are also compared concerning their performance and resource utilization. We have examined the hardware and software development environments used in implementing A/DAS applications and reported their advantages and disadvantages. We provided performance comparisons of usual A/DAS tasks such as traffic sign recognition, road and lane detection, vehicle and pedestrian detection, driver behavior, and multiple tasking. Considering the current research dynamics, A/DAS will remain one of the most popular application fields for vehicular transportation shortly.}
}
@article{HONG2025110009,
title = {Depression level prediction via textual and acoustic analysis},
journal = {Computers in Biology and Medicine},
volume = {190},
pages = {110009},
year = {2025},
issn = {0010-4825},
doi = {https://doi.org/10.1016/j.compbiomed.2025.110009},
url = {https://www.sciencedirect.com/science/article/pii/S0010482525003609},
author = {Jisun Hong and Jihun Lee and Daegil Choi and Jaehyo Jung},
keywords = {Depression analysis block, Human speech recognition system, Multimodal encoding block, Positional encoding, Timestamp extraction block, TIMEX-D, Transformer encoder},
abstract = {Extensive research on automatic depression diagnosis has utilized video data to capture related cues, but data collection is challenging because of privacy concerns. By contrast, voice data offer a less-intrusive assessment method and can be analyzed for features such as simple tones, the expression of negative emotions, and a focus on oneself. Recent advancements in multimodal depression-level prediction using speech and text data have gained traction, but most studies overlook the temporal alignment of these modalities, limiting their analysis of the interaction between speech content and intonation. To overcome these limitations, this study introduces timestamp-integrated multimodal encoding for depression (TIMEX-D) which synchronizes the acoustic features of human speech with corresponding text data to predict depression levels on the basis of their relationship. TIMEX-D comprises three main components: a timestamp extraction block that extracts timestamps from speech and text, a multimodal encoding block that extends positional encoding from transformers to mimic human speech recognition, and a depression analysis block that predicts depression levels while reducing model complexity compared with existing transformers. In experiments using the DAIC-WOZ and EDAIC datasets, TIMEX-D achieved accuracies of 99.17 % and 99.81 %, respectively, outperforming previous methods by approximately 13 %. The effectiveness of TIMEX-D in predicting depression levels can enhance mental health diagnostics and monitoring across various contexts.}
}
@article{CHEN2024103987,
title = {A method for recovering adversarial samples with both adversarial attack forensics and recognition accuracy},
journal = {Computers & Security},
volume = {144},
pages = {103987},
year = {2024},
issn = {0167-4048},
doi = {https://doi.org/10.1016/j.cose.2024.103987},
url = {https://www.sciencedirect.com/science/article/pii/S016740482400292X},
author = {Zigang Chen and Zhen Wang and Yuening Zhou and Fan Liu and Yuhong Liu and Tao Leng and Haihua Zhu},
keywords = {Deep learning, Adversarial example, Adversarial attacks, Adversarial restoration},
abstract = {Adversarial samples deceive machine learning models through small but elaborate modifications that lead to erroneous outputs. The severity of the adversarial sample problem has come to the forefront with the widespread use of machine learning in areas such as security systems, autonomous driving, speech recognition, finance, and medical diagnostics. Malicious attackers can use adversarial samples to circumvent security detection systems, interfere with autonomous driving perception, mislead speech recognition, defraud financial systems, and even cause medical diagnosis errors. The emergence of adversarial samples exposes the vulnerability of existing models and poses challenges for information tracing and forensics after the incident. The main goal of current adversarial sample restoration methods is to improve model robustness. Traditional approaches focus only on improving the model’s classification accuracy, ignoring the importance of adversarial information, which is crucial for understanding the attack mechanism and strengthening future defenses. To address this issue, we propose an adversarial sample restoration method based on the similarity between clean and adversarial sample blocks to balance the needs of adversarial forensics and recognition accuracy. We implement the Fast Gradient Sign Method (FGSM), Basic Iterative Method (BIM), and Momentum Iterative Attack (MIA) attacks on MNIST, F-MNIST, and EMNIST datasets and perform experimental validation. The results demonstrate that our restoration method significantly enhances the model’s classification accuracy across various datasets and attack scenarios. Comparative analysis shows that the restored samples maintain a high similarity with the original adversarial samples, proving the method’s effectiveness. In addition, we performed performance tests on pre- and post-recovery samples. Taking the MNIST dataset as an example, we observed that the model performance metrics, such as MAPE, MAE, RMSE, and VAPE, of the restored samples improved by 88%, 88%, 65%, and 82%, respectively, after using the FGSM attack. This indicates that our restoration method successfully preserves the information of the generation mechanism of the adversarial samples and improves the model’s performance. This approach balances forensic capability and prediction accuracy, demonstrates a new direction in adversarial sample research, and substantially impacts security defense in practical applications.}
}
@article{PANERU2024200165,
title = {Advancing human-computer interaction: AI-driven translation of American Sign Language to Nepali using convolutional neural networks and text-to-speech conversion application},
journal = {Systems and Soft Computing},
volume = {6},
pages = {200165},
year = {2024},
issn = {2772-9419},
doi = {https://doi.org/10.1016/j.sasc.2024.200165},
url = {https://www.sciencedirect.com/science/article/pii/S2772941924000942},
author = {Biplov Paneru and Bishwash Paneru and Khem Narayan Poudyal},
keywords = {Human computer interaction, gTTS, American Sign Language, speech-to-text, OpenCV, Tkinter, VGG16, Convolutional neural networks},
abstract = {Advanced technology that serves people with impairments is severely lacking in Nepal, especially when it comes to helping the hearing impaired communicate. Although sign language is one of the oldest and most organic ways to communicate, there aren't many resources available in Nepal to help with the communication gap between Nepali and American Sign Language (ASL). This study investigates the application of Convolutional Neural Networks (CNN) and AI-driven methods for translating ASL into Nepali text and speech to bridge the technical divide. Two pre-trained transfer learning models, ResNet50 and VGG16, were refined to classify ASL signs using extensive ASL image datasets. The system utilizes the Python gTTS package to translate signs into Nepali text and speech, integrating with an OpenCV video input TKinter-based Graphical User Interface (GUI). With both CNN architectures, the model's accuracy of over 99 % allowed for the smooth conversion of ASL to speech output. By providing a workable solution to improve inclusion and communication, the deployment of an AI-driven translation system represents a significant step in lowering the technological obstacles that disabled people in Nepal must overcome.}
}
@article{GANESH2024623,
title = {Flask-based ASR for Automated Disorder Speech Recognition},
journal = {Procedia Computer Science},
volume = {233},
pages = {623-637},
year = {2024},
note = {5th International Conference on Innovative Data Communication Technologies and Application (ICIDCA 2024)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.03.252},
url = {https://www.sciencedirect.com/science/article/pii/S1877050924006112},
author = {Devalla Bhaskar Ganesh and Yellamma Pachipala and Syed Sania Rizvi and Teena Chowdary Manne and Himavanth Swamy Atchi and V V R Maheswara Rao},
keywords = {Cloud computing, Speech recognition, Disorder speech recognition, Machine learning, Artificial intelligence, Natural language processing},
abstract = {Speech disorders encompass a diverse range of conditions hindering effective communication, stemming from developmental, neurological, or physical factors. These challenges impact daily life and opportunities. Automatic Speech Recognition (ASR) technology emerges as a pivotal solution. ASR, powered by sophisticated algorithms, transcribes spoken language into written text, transcending traditional communication barriers. Tailorable to accommodate unique speech disorders, ASR offers the promise of empowering individuals to articulate their thoughts. Our Python Flask-based ASR(FBASR) applications meticulously crafted to cater to individuals, including children, grappling with speech disorders. It provides a user-friendly platform. Users simply submit a speech audio file in WAV format, and the application transcribes it. Alongside recognized text, it furnishes vital audio metrics. Additionally, it generates visual audio signal and spectrogram representations, all stored efficiently for future reference. The application's profound advantage lies in granting a voice to individuals with speech disorders, facilitating education, employment, and healthcare interactions. Furthermore, it serves as a resource for research and therapy development, promising inclusivity and enriching lives. The proposed work concludes by discussing the future outlook of cloud-based ASR and identifying some of the key areas of research that need to be addressed to make cloud-based DSR systems more accurate, reliable, and accessible.}
}
@article{HUANG2023126629,
title = {A review of deep learning in dentistry},
journal = {Neurocomputing},
volume = {554},
pages = {126629},
year = {2023},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2023.126629},
url = {https://www.sciencedirect.com/science/article/pii/S092523122300752X},
author = {Chenxi Huang and Jiaji Wang and Shuihua Wang and Yudong Zhang},
keywords = {Deep learning, Oral diseases, Image segmentation, Image classification},
abstract = {Oral diseases have a significant impact on human health, often going unnoticed in their early stages. Deep learning, a promising field in artificial intelligence, has shown remarkable success in various domains, especially dentistry. This paper aims to provide an overview of recent research on deep learning applications in dentistry, with a focus on dental imaging. Deep learning algorithms perform well in difficult tasks such as image segmentation and recognition, enabling accurate identification of oral conditions and abnormalities. Integration of deep learning with other oral health data offers a holistic understanding of the relationship between oral and systemic health. However, there are still many challenges that need to be addressed.}
}
@article{GE20243215,
title = {Audio-Text Multimodal Speech Recognition via Dual-Tower Architecture for Mandarin Air Traffic Control Communications},
journal = {Computers, Materials and Continua},
volume = {78},
number = {3},
pages = {3215-3245},
year = {2024},
issn = {1546-2218},
doi = {https://doi.org/10.32604/cmc.2023.046746},
url = {https://www.sciencedirect.com/science/article/pii/S1546221824003047},
author = {Shuting Ge and Jin Ren and Yihua Shi and Yujun Zhang and Shunzhi Yang and Jinfeng Yang},
keywords = {Speech-text multimodal, automatic speech recognition, semantic alignment, air traffic control communications, dual-tower architecture},
abstract = {In air traffic control communications (ATCC), misunderstandings between pilots and controllers could result in fatal aviation accidents. Fortunately, advanced automatic speech recognition technology has emerged as a promising means of preventing miscommunications and enhancing aviation safety. However, most existing speech recognition methods merely incorporate external language models on the decoder side, leading to insufficient semantic alignment between speech and text modalities during the encoding phase. Furthermore, it is challenging to model acoustic context dependencies over long distances due to the longer speech sequences than text, especially for the extended ATCC data. To address these issues, we propose a speech-text multimodal dual-tower architecture for speech recognition. It employs cross-modal interactions to achieve close semantic alignment during the encoding stage and strengthen its capabilities in modeling auditory long-distance context dependencies. In addition, a two-stage training strategy is elaborately devised to derive semantics-aware acoustic representations effectively. The first stage focuses on pre-training the speech-text multimodal encoding module to enhance inter-modal semantic alignment and aural long-distance context dependencies. The second stage fine-tunes the entire network to bridge the input modality variation gap between the training and inference phases and boost generalization performance. Extensive experiments demonstrate the effectiveness of the proposed speech-text multimodal speech recognition method on the ATCC and AISHELL-1 datasets. It reduces the character error rate to 6.54% and 8.73%, respectively, and exhibits substantial performance gains of 28.76% and 23.82% compared with the best baseline model. The case studies indicate that the obtained semantics-aware acoustic representations aid in accurately recognizing terms with similar pronunciations but distinctive semantics. The research provides a novel modeling paradigm for semantics-aware speech recognition in air traffic control communications, which could contribute to the advancement of intelligent and efficient aviation safety management.}
}
@article{AYDOGMUS2023107120,
title = {An automated voice command classification model based on an attention-deep convolutional neural network for industrial automation system},
journal = {Engineering Applications of Artificial Intelligence},
volume = {126},
pages = {107120},
year = {2023},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2023.107120},
url = {https://www.sciencedirect.com/science/article/pii/S0952197623013040},
author = {Omur Aydogmus and Mustafa Can Bingol and Gullu Boztas and Turker Tuncer},
keywords = {Deep feature extraction, Industrial automation, Programmable logic controller, SCADA, Speech recognition},
abstract = {In this research, a method was developed for utilizing voice commands with programmable logic controllers (PLCs) and supervisory control and data acquisition (SCADA) systems, which are commonly utilized in industrial automation. This approach incorporates artificial intelligence to enable human–machine interaction, aligning with the trends of Industry 4.0. A deep neural network was specifically designed for speech recognition, eliminating the need for reliance on any pre-existing speech-to-text engines. The objective was to create a model that is accurate and compact in size, making it suitable for embedded systems within industrial systems. To train the deep learning network, 21,600 sound files were generated. These files combined real factory noise with a synthetic dataset of human speech, forming a dataset comprising 60 different classes of voice commands. These commands encompassed actions like starting, stopping, and operating at various speeds for 10 motors controlled by the automation system. After applying the Mel-frequency cepstral coefficient (MFCC) to the voice commands, the resulting data was directly fed into the proposed network. The network achieved an impressive accuracy rate of 99.73%. Notably, the proposed network outperformed even networks several times its size.}
}
@article{FERNANDEZGONZALEZ202343,
title = {Discontinuous grammar as a foreign language},
journal = {Neurocomputing},
volume = {524},
pages = {43-58},
year = {2023},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2022.12.045},
url = {https://www.sciencedirect.com/science/article/pii/S092523122201551X},
author = {Daniel Fernández-González and Carlos Gómez-Rodríguez},
keywords = {Natural language processing, Computational linguistics, Parsing, Discontinuous constituent parsing, Neural network, Deep learning, Sequence-to-sequence model},
abstract = {In order to achieve deep natural language understanding, syntactic constituent parsing is a vital step, highly demanded by many artificial intelligence systems to process both text and speech. One of the most recent proposals is the use of standard sequence-to-sequence models to perform constituent parsing as a machine translation task, instead of applying task-specific parsers. While they show a competitive performance, these text-to-parse transducers are still lagging behind classic techniques in terms of accuracy, coverage and speed. To close the gap, we here extend the framework of sequence-to-sequence models for constituent parsing, not only by providing a more powerful neural architecture for improving their performance, but also by enlarging their coverage to handle the most complex syntactic phenomena: discontinuous structures. To that end, we design several novel linearizations that can fully produce discontinuities and, for the first time, we test a sequence-to-sequence model on the main discontinuous benchmarks, obtaining competitive results on par with task-specific discontinuous constituent parsers and achieving state-of-the-art scores on the (discontinuous) English Penn Treebank.}
}
@article{AHMAD20243129,
title = {Enhancing ChatGPT’s Querying Capability with Voice-Based Interaction and CNN-Based Impair Vision Detection Model},
journal = {Computers, Materials and Continua},
volume = {78},
number = {3},
pages = {3129-3150},
year = {2024},
issn = {1546-2218},
doi = {https://doi.org/10.32604/cmc.2024.045385},
url = {https://www.sciencedirect.com/science/article/pii/S1546221824002996},
author = {Awais Ahmad and Sohail Jabbar and Sheeraz Akram and Anand Paul and Umar Raza and Nuha Mohammed Alshuqayran},
keywords = {Accessibility in conversational AI, CNN-based impair vision detection, ChatGPT, voice-based interaction, recommender system},
abstract = {This paper presents an innovative approach to enhance the querying capability of ChatGPT, a conversational artificial intelligence model, by incorporating voice-based interaction and a convolutional neural network (CNN)-based impaired vision detection model. The proposed system aims to improve user experience and accessibility by allowing users to interact with ChatGPT using voice commands. Additionally, a CNN-based model is employed to detect impairments in user vision, enabling the system to adapt its responses and provide appropriate assistance. This research tackles head-on the challenges of user experience and inclusivity in artificial intelligence (AI). It underscores our commitment to overcoming these obstacles, making ChatGPT more accessible and valuable for a broader audience. The integration of voice-based interaction and impaired vision detection represents a novel approach to conversational AI. Notably, this innovation transcends novelty; it carries the potential to profoundly impact the lives of users, particularly those with visual impairments. The modular approach to system design ensures adaptability and scalability, critical for the practical implementation of these advancements. Crucially, the solution places the user at its core. Customizing responses for those with visual impairments demonstrates AI’s potential to not only understand but also accommodate individual needs and preferences.}
}
@article{GOLDENTHAL2021106975,
title = {Not All AI are Equal: Exploring the Accessibility of AI-Mediated Communication Technology},
journal = {Computers in Human Behavior},
volume = {125},
pages = {106975},
year = {2021},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2021.106975},
url = {https://www.sciencedirect.com/science/article/pii/S0747563221002983},
author = {Emma Goldenthal and Jennifer Park and Sunny X. Liu and Hannah Mieczkowski and Jeffrey T. Hancock},
keywords = {Artificial intelligence, Digital access, Digital literacy, AI-Mediated Communication, Socioeconomic factors},
abstract = {While AI technologies and tools offer various potential benefits to their users, it is not clear whether opportunities to access these benefits are equally accessible to all. We examine this gap between availability and accessibility as it relates to the adoption of AI-Mediated Communication (AI-MC) tools, which enable interpersonal communication where an intelligent agent operates on behalf of a communicator. Upon defining six functional AI-MC types (voice-assisted communication, language correction, predictive text suggestion, transcription, translation, personalized language learning) we conducted an online survey of 519 U.S. participants that combined closed- and open-ended measures. Our quantitative results revealed how AI-MC adoption is related to software, device, and internet access for tools such as voice-assisted communication; demographic factors such as age, education and income in the case of translation and transcription tools; and some components of AI-MC literacy for specific functional tools. Our qualitative analyses provide additional nuance for these findings, and we articulate a number of barriers to access, understanding, and usage of AI-MC tools, which we suggest hinder AI-MC accessibility for user groups traditionally disadvantaged by one-size-fits-all technological tools. We end with a call for broadly addressing accessibility concerns within the digital technology industry.}
}
@article{BILIKA2024103617,
title = {Hello me, meet the real me: Voice synthesis attacks on voice assistants},
journal = {Computers & Security},
volume = {137},
pages = {103617},
year = {2024},
issn = {0167-4048},
doi = {https://doi.org/10.1016/j.cose.2023.103617},
url = {https://www.sciencedirect.com/science/article/pii/S0167404823005278},
author = {Domna Bilika and Nikoletta Michopoulou and Efthimios Alepis and Constantinos Patsakis},
keywords = {Voice assistants, Voice synthesis, Android, IOS, Security, Synthesised voice},
abstract = {The radical advances in telecommunications and computer science have enabled a myriad of applications and novel seamless interactions with computing interfaces. Voice Assistants (VAs) have become the norm for smartphones, and millions of VAs incorporated in smart devices are used to control these devices in the smart home context. Previous research has shown that they are prone to attacks, leading vendors to implement countermeasures. One of these measures is to allow only a specific individual, the device's owner, to perform potentially dangerous tasks that may disclose personal information, involve monetary transactions, etc. To understand the extent to which VAs provide the necessary protection to their users, we experimented with two of the most widely used VAs, which the participants trained. We then utilised voice synthesis, using samples provided by participants, to synthesise commands that were used to trigger the corresponding VA and perform a dangerous task. Our extensive results showed that more than 30% of our audio synthesis attacks were successful and at least one successful attack for more than half of the participants. Moreover, they illustrate statistically significant variation among vendors and, in one case, even gender bias. The outcomes are rather alarming and require the deployment of further countermeasures to prevent exploitation, as the number of VAs in use is currently comparable to the world population.}
}
@article{TRIGUERO2024102135,
title = {General Purpose Artificial Intelligence Systems (GPAIS): Properties, definition, taxonomy, societal implications and responsible governance},
journal = {Information Fusion},
volume = {103},
pages = {102135},
year = {2024},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2023.102135},
url = {https://www.sciencedirect.com/science/article/pii/S1566253523004517},
author = {Isaac Triguero and Daniel Molina and Javier Poyatos and Javier {Del Ser} and Francisco Herrera},
keywords = {General-purpose AI, Meta-learning, Reinforcement learning, Neuroevolution, Few-shot learning, AutoML, Transfer learning, Generative AI, Large language models},
abstract = {Most applications of Artificial Intelligence (AI) are designed for a confined and specific task. However, there are many scenarios that call for a more general AI, capable of solving a wide array of tasks without being specifically designed for them. The term General Purpose Artificial Intelligence Systems (GPAIS) has been defined to refer to these AI systems. To date, the possibility of an Artificial General Intelligence, powerful enough to perform any intellectual task as if it were human, or even improve it, has remained an aspiration, fiction, and considered a risk for our society. Whilst we might still be far from achieving that, GPAIS is a reality and sitting at the forefront of AI research. This work discusses existing definitions for GPAIS and proposes a new definition that allows for a gradual differentiation among types of GPAIS according to their properties and limitations. We distinguish between closed-world and open-world GPAIS, characterising their degree of autonomy and ability based on several factors such as adaptation to new tasks, competence in domains not intentionally trained for, ability to learn from few data, or proactive acknowledgement of their own limitations. We then propose a taxonomy of approaches to realise GPAIS, describing research trends such as the use of AI techniques to improve another AI (commonly referred to as AI-powered AI) or (single) foundation models. As a prime example, we delve into generative AI (GenAI), aligning them with the terms and concepts presented in the taxonomy. Similarly, we explore the challenges and prospects of multi-modality, which involves fusing various types of data sources to expand the capabilities of GPAIS. Through the proposed definition and taxonomy, our aim is to facilitate research collaboration across different areas that are tackling general purpose tasks, as they share many common aspects. Finally, with the goal of providing a holistic view of GPAIS, we discuss the current state of GPAIS, its prospects, implications for our society, and the need for regulation and governance of GPAIS to ensure their responsible and trustworthy development.}
}
@article{ZHOU2024102261,
title = {Efficient lower layers parameter decoupling personalized federated learning method of facial expression recognition for home care robots},
journal = {Information Fusion},
volume = {106},
pages = {102261},
year = {2024},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2024.102261},
url = {https://www.sciencedirect.com/science/article/pii/S1566253524000393},
author = {Xu Zhou and Jie Li and Gongjin Lan and Rongrong Ni and Angelo Cangelosi and Jiaxin Wang and Xiaofeng Liu},
keywords = {Federated learning, Privacy preservation, Home care robot, Facial expression recognition(FER), Personalization, Lightweight deep convolutional neural networks},
abstract = {Facial expression recognition (FER) is a crucial and pivotal functionality for home care robots that engage in intimate interactions with human individuals. However, the potential privacy risk associated with home care robots resides in their acquisition of facial information during expression recognition and subsequent data uploading for model updates. Federated learning (FL) can safeguard data privacy while enabling machine learning, yet its application to home care robots poses several challenges, including non-independent and non-identically distributed collected data, limited communication and computation capabilities on the robot side. However, limited research has been conducted in this area. In this paper, we propose a lightweight neural network architecture for the federated FER model on home care robots. We also introduce an efficient and simple lower-layer personalized FL method that optimizes local personalized models by exchanging fewer parameters. Furthermore, we implement a demo on real physical robots NAO to demonstrate how our federated model improves the performance of local FER models in non-IID data settings. The results demonstrate that our approach achieves competitive performance on four simulated non-IID facial expression recognition (FER) datasets, comparable to larger network models and state-of-the-art algorithms. There is an average difference of approximately 3% from the best algorithm results on three datasets, while outperforming the best algorithm by 2% on one dataset. The evaluation of our methods on two real NAO robots shows that the overall performance improvement of our federated model over the locally independent model is about 20% on average. The open-source code is available at https://github.com/zxecho/FESAHR.}
}
@article{VALERO202312,
title = {Analysis of security and data control in smart personal assistants from the user’s perspective},
journal = {Future Generation Computer Systems},
volume = {144},
pages = {12-23},
year = {2023},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2023.02.009},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X2300050X},
author = {Cayetano Valero and Jaime Pérez and Sonia Solera-Cotanilla and Mario Vega-Barbas and Guillermo Suarez-Tangil and Manuel Alvarez-Campana and Gregorio López},
keywords = {Cybersecurity, Data control, Internet of things, Minors, Smart personal assistants, Testing methodology},
abstract = {Advances in the fields of the Internet of Things, Speech Recognition and Artificial Intelligence have facilitated the development of Smart Personal Assistants. As a result, Smart Personal Assistants currently allow requesting a wide range of tasks naturally and intuitively through voice interaction. Their wide popularity, together with the high technological complexity of their environments, have made them an attractive target from a security point of view. Recent works have shown some of the security and privacy issues they stand upon. In this work, we propose a methodology to carry out a systematic security analysis of Smart Personal Assistants using a comprehensive set of tests designed to measure issues around the installation, the interaction, key functionality, and overall Security and Privacy controls. We apply this methodology to analyse security and data control in predominant commercial Smart Personal Assistants (SPA), including Apple HomePod, Google Home and Nest, Amazon Echo (Show and Dot), and Facebook Portal. The main findings of our research are: (i) SPA are not resilient to voice replay attacks; (ii) their skills activation mechanisms can be significantly improved to be more reliable in multi-user households; (iii) the users’ control to restrict the collection and access of Personally Identifiable Information can be also improved; (iv) they lack configurations adapted to minors, which should be included to make them more appropriate for a segment of users who interact more and more with them and have especially high regulatory requirements regarding security and data protection. Among the many hot research topics within this area, we find voice authentication and authorization especially interesting since they may push the usability of Smart Personal Assistants further, as long as they are robust enough from the security perspective.}
}
@article{VANMIL2022105689,
title = {A Matter of (Joint) control? Virtual assistants and the general data protection regulation},
journal = {Computer Law & Security Review},
volume = {45},
pages = {105689},
year = {2022},
issn = {2212-473X},
doi = {https://doi.org/10.1016/j.clsr.2022.105689},
url = {https://www.sciencedirect.com/science/article/pii/S026736492200036X},
author = {Jurriaan {van Mil} and João Pedro Quintais},
keywords = {General data protection regulation, Controller, Joint controller, Household exception, Virtual assistant, Google assistant},
abstract = {This article provides an overview and critical examination of the rules for determining who qualifies as controller or joint controller under the General Data Protection Regulation. Using Google Assistant – an artificial intelligence-driven virtual assistant – as a case study, we argue that these rules are overreaching and difficult to apply in the present-day information society and Internet of Things environments. First, as a consequence of recent developments in case law and supervisory guidance, these rules lead to a complex and ambiguous test to determine (joint) control. Second, due to advances in technological applications and business models, it is increasingly challenging to apply such rules to contemporary processing operations. In particular, as illustrated by the Google Assistant, individuals will likely be qualified as joint controllers, together with Google and also third-party developers, for at least the collection and possible transmission of other individuals’ personal data via the virtual assistant. Third, we identify follow-on issues relating to the apportionment of responsibilities between joint controllers and the effective and complete protection of data subjects. We conclude by questioning whether the framework for determining who qualifies as controller or joint controller is future-proof and normatively desirable.}
}
@article{KADAM2021100,
title = {Cognitive Evaluation of Machine Learning Agents},
journal = {Cognitive Systems Research},
volume = {66},
pages = {100-121},
year = {2021},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2020.11.003},
url = {https://www.sciencedirect.com/science/article/pii/S1389041720300978},
author = {Suvarna Kadam and Vinay Vaidya},
keywords = {Cognition Framework, Machine Learning, Cognitive Evaluation, Machine Cognition, Cognition Metrics, Evaluation Metrics},
abstract = {Advances in applying statistical Machine Learning (ML) led to several claims of human-level or near-human performance in tasks such as image classification & speech recognition. Such claims are unscientific primarily for two reasons, (1) They incorrectly enforce the notion that task-specific performance can be treated as manifestation of General Intelligence and (2) They are not verifiable as currently there is no set benchmark for measuring human-like cognition in a machine learning agent. Moreover, ML agent’s performance is influenced by knowledge ingested in it by its human designers. Therefore, agent’s performance may not necessarily reflect its true cognition. In this paper, we propose a framework that draws parallels from human cognition to measure machine’s cognition. Human cognitive learning is quite well studied in developmental psychology with frameworks and metrics in place to measure actual learning. To either believe or refute the claims of human-level performance of machine learning agent, we need scientific methodology to measure its cognition. Our framework formalizes incremental implementation of human-like cognitive processes in ML agents with an implicit goal to measure it. The framework offers guiding principles for measuring, (1) Task-specific machine cognition and (2) General machine cognition that spans across tasks. The framework also provides guidelines for building domain-specific task taxonomies to cognitively profile tasks. We demonstrate application of the framework with a case study where two ML agents that perform Vision and NLP tasks are cognitively evaluated.}
}
@article{CHUBB2022100403,
title = {Interactive storytelling for children: A case-study of design and development considerations for ethical conversational AI},
journal = {International Journal of Child-Computer Interaction},
volume = {32},
pages = {100403},
year = {2022},
issn = {2212-8689},
doi = {https://doi.org/10.1016/j.ijcci.2021.100403},
url = {https://www.sciencedirect.com/science/article/pii/S2212868921000921},
author = {Jennifer Chubb and Sondess Missaoui and Shauna Concannon and Liam Maloney and James Alfred Walker},
keywords = {Conversational AI, Intelligent personal assistants, Ethics of AI, Moral and societal impact, Automatic speech recognition, Natural language processing, Child development},
abstract = {Conversational Artificial Intelligence (CAI) systems and Intelligent Personal Assistants (IPA), such as Alexa, Cortana, Google Home and Siri are becoming ubiquitous in our lives, including those of children, the implications of which is receiving increased attention, specifically with respect to the effects of these systems on children’s cognitive, social and linguistic development. Recent advances address the implications of CAI with respect to privacy, safety, security, and access. However, there is a need to connect and embed the ethical and technical aspects in the design. Using a case-study of a research and development project focused on the use of CAI in storytelling for children, this paper reflects on the social context within a specific case of technology development, as substantiated and supported by argumentation from within the literature. It describes the decision making process behind the recommendations made on this case for their adoption in the creative industries. Further research that engages with developers and stakeholders in the ethics of storytelling through CAI is highlighted as a matter of urgency.}
}
@article{KHALAFALLAH2024101864,
title = {Speech corpus for Medina dialect},
journal = {Journal of King Saud University - Computer and Information Sciences},
volume = {36},
number = {2},
pages = {101864},
year = {2024},
issn = {1319-1578},
doi = {https://doi.org/10.1016/j.jksuci.2023.101864},
url = {https://www.sciencedirect.com/science/article/pii/S1319157823004184},
author = {Haneen Bahjat Khalafallah and Mohamed Abdel Fattah and Ruqayya Abdulrahman},
keywords = {Machine Learning (ML), Natural Language Processing (NLP), Automatic Speech Recognition, Arabic ASR Speech Corpus, Arabic Dialects, CMU Sphinx},
abstract = {Automatic Speech Recognition (ASR) has standard rules which must be followed and considered carefully. Some difficulties that lead to less ASR performance is variations in pronunciation and small words misrecognition. Arabic ASR faces some challenges like difficulty in obtaining corpora for spoken dialects. Obtaining a wide range of diacritized text as well as the enormous number of word forms is considered a major challenge due to the Arabic language morphology richness and its’ letters capability to be written without diacritics. Although Arabic is one of the most popular languages, Arabic ASR systems are still rare compared with other languages. As ASR systems depend primarily on speech corpuses, Arabic ASR systems requires specific-dialect speech corpuses. Such speech corpuses are still deficient, costly, nor sometimes exists. In this research, we contribute to overcome the lack of speech recognition and misunderstanding for one of the most famous dialects in Saudi Arabia, Medina. We created a brand-new corpus “Haneen Corpus“, which consists of 70,364 tokens that have been uttered using Medina dialect, and constructed a dictionary using 64 phonemes to analyse the correct pronunciation of words. Our Medina Dialect ASR System exploited Hidden Markov Models (HMM) that achieved 92.09 % speech recognition accuracy.}
}
@article{MA2025128916,
title = {Fully end-to-end EEG to speech translation using multi-scale optimized dual generative adversarial network with cycle-consistency loss},
journal = {Neurocomputing},
volume = {616},
pages = {128916},
year = {2025},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2024.128916},
url = {https://www.sciencedirect.com/science/article/pii/S0925231224016874},
author = {Chen Ma and Yue Zhang and Yina Guo and Xin Liu and Hong Shangguan and Juan Wang and Luqing Zhao},
keywords = {Brain–computer interface (BCI), Fully end-to-end, Dual–dual generative adversarial network (Dual-DualGAN), Dual generative adversarial network based on multi-scale optimization and cycle-consistency loss (MSCC-dualGAN), Cross-domain},
abstract = {Decoding auditory evoked electroencephalographic (EEG) signals to correlate them with speech acoustic features and construct transitional signals between different domain signals is a challenging and fascinating research topic. Brain–computer interface (BCI) technologies that incorporate auditory evoked potentials (AEPs) can not only leverage encoder–decoder architectures for signal decoding, but also employ generative adversarial networks (GANs) to translate from human neural activity to speech (T-HNAS). However, in previous research, the cascading ratio of transitional signals leads to varying degrees of information loss in the two-domain signals, and the optimal ratio of transitional signals differs across datasets, impacting the translation effectiveness. To address these issues, an improved dual generative adversarial network based on multi-scale optimization and cycle-consistency loss (MSCC-DualGAN) is proposed. We leverage the feature of cycle consistency loss, which facilitates cross-modal signal conversion, to replace transitional signals and maintain the integrity of signals in both domains during the loss computation process. Multi-scale optimization is utilized to refine the details of signals downsampled by the network, improving the similarity between features, thus enabling efficient, fully end-to-end EEG to speech translation. Furthermore, to validate the efficacy of this network, we construct a new EEG dataset and conduct studies using metrics such as mel cepstral distortion (MCD), pearson correlation coefficient (PCC), and structural similarity index measure (SSIM). Experimental results demonstrate that this new network significantly outperforms previous methods on auditory stimulus datasets.}
}
@article{SHANG2024200436,
title = {Multimodal fusion: A study on speech-text emotion recognition with the integration of deep learning},
journal = {Intelligent Systems with Applications},
volume = {24},
pages = {200436},
year = {2024},
issn = {2667-3053},
doi = {https://doi.org/10.1016/j.iswa.2024.200436},
url = {https://www.sciencedirect.com/science/article/pii/S2667305324001108},
author = {Yanan Shang and Tianqi Fu},
keywords = {Multimodal fusion, Deep learning, Glove model, BiGRU, Emotion recognition},
abstract = {Recognition of various human emotions holds significant value in numerous real-world scenarios. This paper focuses on the multimodal fusion of speech and text for emotion recognition. A 39-dimensional Mel-frequency cepstral coefficient (MFCC) was used as a feature for speech emotion. A 300-dimensional word vector obtained through the Glove algorithm was used as the feature for text emotion. The bidirectional gate recurrent unit (BiGRU) method in deep learning was added for extracting deep features. Subsequently, it was combined with the multi-head self-attention (MHA) mechanism and the improved sparrow search algorithm (ISSA) to obtain the ISSA-BiGRU-MHA method for emotion recognition. It was validated on the IEMOCAP and MELD datasets. It was found that MFCC and Glove word vectors exhibited superior recognition effects as features. Comparisons with the support vector machine and convolutional neural network methods revealed that the ISSA-BiGRU-MHA method demonstrated the highest weighted accuracy and unweighted accuracy. Multimodal fusion achieved weighted accuracies of 76.52 %, 71.84 %, 66.72 %, and 62.12 % on the IEMOCAP, MELD, MOSI, and MOSEI datasets, suggesting better performance than unimodal fusion. These results affirm the reliability of the multimodal fusion recognition method, showing its practical applicability.}
}
@article{GABER2021122,
title = {Fault Detection based on Deep Learning for Digital VLSI Circuits},
journal = {Procedia Computer Science},
volume = {194},
pages = {122-131},
year = {2021},
note = {18th International Learning & Technology Conference 2021},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2021.10.065},
url = {https://www.sciencedirect.com/science/article/pii/S1877050921021062},
author = {Lamya Gaber and Aziza I. Hussein and Mohammed Moness},
keywords = {Design Debugging, Sparse Autoencoder, ML, Deep Learning},
abstract = {As growing complexity of digital VLSI circuits, fault detection and correction processes have been the most crucial phases during IC design. Many CAD tools and formal approaches have been used for debugging and localizing different kinds of design bugs. However, the search space explosion problem remains the main problem for IC designers. Recently, Artificial intelligence and machine learning models have been expanded in feature extraction and reduction models. In this paper, we introduce a new fault detection model based on deep learning for extracting features and detecting faults from large-sized digital circuits. The main goal of the proposed model is to avoid the search space using stacked sparse autoencoder, a specific type of artificial neural network. The model consists of three phases: test pattern generation using ATALANTA software, feature reduction using SSAE and classification for fault detection. Test vectors are utilized in SSAE as a training data for unsupervised learning phase. The performance of feature extraction is tested by changing the architecture of SSAE network and sparsity constraint. The proposed algorithm has been implemented using eight combinational digital circuits from ISCAS’85. From experimental results, the maximum fault coverage using ATALANTA tool delivers around 99.2% using ISCAS’85. In addition, the maximum validation accuracy of proposed SSAE model delivers around 99.7% in feature reduction phase.}
}
@article{DRYDAKIS2021106661,
title = {Mobile applications aiming to facilitate immigrants’ societal integration and overall level of integration, health and mental health. Does artificial intelligence enhance outcomes?},
journal = {Computers in Human Behavior},
volume = {117},
pages = {106661},
year = {2021},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2020.106661},
url = {https://www.sciencedirect.com/science/article/pii/S0747563220304088},
author = {Nick Drydakis},
keywords = {Mobile applications, m-Integration, m-Health, Artificial intelligence, Integration, Immigrants, Refugees, Health, Mental health},
abstract = {Using panel data on immigrant populations from European, Asian and African countries the study estimates positive associations between the number of mobile applications in use aiming to facilitate immigrants' societal integration (m-Integration) and increased level of integration (Ethnosizer), good overall health (EQ-VAS) and mental health (CESD-20). It is estimated that the patterns are gender sensitive. In addition, it is found that m-Integration applications in relation to translation and voice assistants, public services, and medical services provide the highest returns on immigrants' level of integration, health/mental health status. For instance, translation and voice assistant applications are associated with a 4% increase in integration and a 0.8% increase in good overall health. Moreover, m-Integration applications aided by artificial intelligence (AI) are associated with increased health/mental health and integration levels among immigrants. We indicate that AI by providing customized search results, peer reviewed e-learning, professional coaching on pronunciation, real-time translations, and virtual communication for finding possible explanations for health conditions might bring better quality services facilitating immigrants' needs. This is the first known study to introduce the term ‘m-Integration’, quantify associations between applications, health/mental health and integration for immigrants, and assess AI's role in enhancing the aforementioned outcomes.}
}
@article{GAO202295,
title = {An Optimized Convolutional Neural Network with Combination Blocks for Chinese Sign Language Identification},
journal = {CMES - Computer Modeling in Engineering and Sciences},
volume = {132},
number = {1},
pages = {95-117},
year = {2022},
issn = {1526-1492},
doi = {https://doi.org/10.32604/cmes.2022.019970},
url = {https://www.sciencedirect.com/science/article/pii/S1526149222003629},
author = {Yalan Gao and Yanqiong Zhang and Xianwei Jiang},
keywords = {Convolutional neural network, combination blocks, Chinese sign language, batch normalization, dropout, Leaky ReLU, -fold cross-validation},
abstract = {(Aim) Chinese sign language is an essential tool for hearing-impaired to live, learn and communicate in deaf communities. Moreover, Chinese sign language plays a significant role in speech therapy and rehabilitation. Chinese sign language identification can provide convenience for those hearing impaired people and eliminate the communication barrier between the deaf community and the rest of society. Similar to the research of many biomedical image processing (such as automatic chest radiograph processing, diagnosis of chest radiological images, etc.), with the rapid development of artificial intelligence, especially deep learning technologies and algorithms, sign language image recognition ushered in the spring. This study aims to propose a novel sign language image recognition method based on an optimized convolutional neural network. (Method) Three different combinations of blocks: Conv-BN-ReLU-Pooling, Conv-BN-ReLU, Conv-BN-ReLU-BN were employed, including some advanced technologies such as batch normalization, dropout, and Leaky ReLU. We proposed an optimized convolutional neural network to identify 1320 sign language images, which was called as CNN-CB method. Totally ten runs were implemented with the hold-out randomly set for each run. (Results) The results indicate that our CNN-CB method gained an overall accuracy of 94.88 ± 0.99%. (Conclusion) Our CNN-CB method is superior to thirteen state-of-the-art methods: eight traditional machine learning approaches and five modern convolutional neural network approaches.}
}
@article{ILAGAN20241124,
title = {A prototype of a conversational virtual university support agent powered by a large language model that addresses inquiries about policies in the student handbook},
journal = {Procedia Computer Science},
volume = {239},
pages = {1124-1131},
year = {2024},
note = {CENTERIS – International Conference on ENTERprise Information Systems / ProjMAN - International Conference on Project MANagement / HCist - International Conference on Health and Social Care Information Systems and Technologies 2023},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.06.278},
url = {https://www.sciencedirect.com/science/article/pii/S1877050924015217},
author = {Joseph Benjamin Ilagan and Jose Ramon Ilagan},
keywords = {Conversational User Experience, Conversational agents, Natural language processing, Large language model, Chatbot},
abstract = {Universities gain a competitive advantage by deliberately improving overall service, student, faculty, and staff experience, leading to attractiveness, retention, and improved outcomes. Quality services are achieved partly by addressing employee satisfaction, specifically in the work environment. This paper presents a prototype study of a virtual university support agent, a system grounded in a Large Language Model (LLM) engineered to address inquiries from university students, faculty and staff related to the student handbook. The study investigates the integration of generative artificial intelligence and natural conversation properties inherent in LLMs to overcome customer service shortcomings identified in previous chatbot applications. The LLMs’ susceptibility to ‘hallucination’ is mitigated through a combined approach of few-shot learning and chain of thought libraries in the training phase. The information core of this system comprises student handbook PDF files, from which an algorithm extracts and structures data to be utilized by the LLM. As a result, the university support agent facilitates a viable Q&A interface for students, faculty, and administrators to inquire about university guidelines and policies.}
}
@article{BADE2024268,
title = {Lexicon-based Language Relatedness Analysis},
journal = {Procedia Computer Science},
volume = {244},
pages = {268-277},
year = {2024},
note = {6th International Conference on AI in Computational Linguistics},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.10.200},
url = {https://www.sciencedirect.com/science/article/pii/S1877050924030011},
author = {Girma Yohannis Bade and Olga Kolesnikova and José Luis Oropeza and Grigori Sidorov},
keywords = {Computational linguistics, NLP, cosine similarity, lexicon relatedness, Omotic languages},
abstract = {The field of computational linguistics has been impacting various issues in language disciplines. The enormous growth of machine learning algorithms and Natural Language Processing (NLP) empowers its advancement and brings huge benefits to societies. For instance, machine translation, text summarization, sentence auto-completion, and sentiment analysis are a few of its benefits. However, leveraging this opportunity for low-resourced languages is challenging due to the lack of available electronic datasets. This paper presents a lexicon-based language relatedness analysis on Ethiopian low-resourced languages. The languages Wolaita, Dawuro, Gamo, and Gofa belong to the Ethiopian Omotic language family and share rich linguistic cultures and similarities. However, the extent of their inter-relatedness remains unknown. To address this gap, we collected and prepared novel corpora from the Bible and academic texts. We employed the TF-IDF technique for feature extraction and used the cosine similarity method to measure the similarities among these languages. In addition to cosine similarity, we used Euclidean distance to measure the spatial distances between the languages. The experiment results showed that Wolaita and Gofa exhibited high relatedness (33.4%), while Dawuro and Gamo demonstrated low relatedness (12.1%).}
}
@article{MUHAMAD2024100096,
title = {Kurdish end-to-end speech synthesis using deep neural networks},
journal = {Natural Language Processing Journal},
volume = {8},
pages = {100096},
year = {2024},
issn = {2949-7191},
doi = {https://doi.org/10.1016/j.nlp.2024.100096},
url = {https://www.sciencedirect.com/science/article/pii/S294971912400044X},
author = {Sabat Salih Muhamad and Hadi Veisi and Aso Mahmudi and Abdulhady Abas Abdullah and Farhad Rahimi},
keywords = {Central Kurdish language, Deep learning, Speech synthesis, Tacotron2, End-to-end, WaveGlow vocoder},
abstract = {This article introduces an end-to-end text-to-speech (TTS) system for the low-resourced language of Central Kurdish (CK, also known as Sorani) and tackles the challenges associated with limited data availability. We have compiled a dataset suitable for end-to-end text-to-speech that includes 21 h of CK female voice paired with corresponding texts. To identify the optimal performing system, we employed Tacotron2, an end-to-end deep neural network for speech synthesis, in three training experiments. The process involves training Tacotron2 using a pre-trained English system, followed by training two models from scratch with full and intonationally balanced datasets. We evaluated the effectiveness of these models using Mean Opinion Score (MOS), a subjective evaluation metric. Our findings demonstrate that the model trained from scratch on the full CK dataset surpasses both the model trained with the intonationally balanced dataset and the model trained using a pre-trained English model in terms of naturalness and intelligibility by achieving a MOS of 4.78 out of 5.}
}
@article{LIM2025109618,
title = {A lightweight approach based on cross-modality for depression detection},
journal = {Computers in Biology and Medicine},
volume = {186},
pages = {109618},
year = {2025},
issn = {0010-4825},
doi = {https://doi.org/10.1016/j.compbiomed.2024.109618},
url = {https://www.sciencedirect.com/science/article/pii/S0010482524017037},
author = {Eunchae Lim and Min Jhon and Ju-Wan Kim and Soo-Hyung Kim and Seungwon Kim and Hyung-Jeong Yang},
keywords = {Depression detection, Cross-modality, Multimodal fusion, Depression dataset},
abstract = {Early detection of depression is crucial because depression can lead to suicide if the symptoms are left unrecognized or untreated. In hospitals, self-administered questionnaires and interviews are employed to diagnose depression. Although doctors spend considerable time interviewing patients to understand their conditions, depression is a heterogeneous syndrome that makes accurate diagnosis challenging. Therefore, the biological aspects of depression must be investigated to address the limitations of traditional diagnostic methods. Audio data can be easily collected in daily life. Hence, we propose a multimodal fusion cross-modality model that applies audio and text to detect depression. The proposed model achieved F1-scores of 0.67, 0.81, and 0.61 on the Distress Analysis Interview Corpus, Emotional Audio and Textual Depression Corpus, and Korean Depression datasets. The model is designed to be lightweight, reducing the number of parameters while maintaining model accuracy with fewer parameters so that it can be employed in pervasive devices. We used English, Chinese, and Korean depression datasets to evaluate the performance of the proposed model across languages. The cross-language experiments confirm that the proposed model can be applied in other languages, even if the model is not trained in the same vocabulary. This finding suggests that the model has learned distinctive depression characteristics by combining nonlinguistic speech features and linguistic textual features. Therefore, this research is expected to detect depression in everyday life across languages and devices.}
}
@article{ALI20212209,
title = {Deep Image Restoration Model: A Defense Method Against Adversarial Attacks},
journal = {Computers, Materials and Continua},
volume = {71},
number = {2},
pages = {2209-2224},
year = {2021},
issn = {1546-2218},
doi = {https://doi.org/10.32604/cmc.2022.020111},
url = {https://www.sciencedirect.com/science/article/pii/S1546221821001697},
author = {Kazim Ali and Adnan N. Quershi and Ahmad Alauddin Bin Arifin and Muhammad Shahid Bhatti and Abid Sohail and Rohail Hassan},
keywords = {Computer vision, deep learning, convolutional neural networks, adversarial examples, adversarial attacks, adversarial defenses},
abstract = {These days, deep learning and computer vision are much-growing fields in this modern world of information technology. Deep learning algorithms and computer vision have achieved great success in different applications like image classification, speech recognition, self-driving vehicles, disease diagnostics, and many more. Despite success in various applications, it is found that these learning algorithms face severe threats due to adversarial attacks. Adversarial examples are inputs like images in the computer vision field, which are intentionally slightly changed or perturbed. These changes are humanly imperceptible. But are misclassified by a model with high probability and severely affects the performance or prediction. In this scenario, we present a deep image restoration model that restores adversarial examples so that the target model is classified correctly again. We proved that our defense method against adversarial attacks based on a deep image restoration model is simple and state-of-the-art by providing strong experimental results evidence. We have used MNIST and CIFAR10 datasets for experiments and analysis of our defense method. In the end, we have compared our method to other state-of-the-art defense methods and proved that our results are better than other rival methods.}
}
@article{COLABIANCHI20251555,
title = {Application of a digital intelligent assistant to support industrial processes: the case of adaptive allocation in the face of cyber attacks},
journal = {Procedia Computer Science},
volume = {253},
pages = {1555-1564},
year = {2025},
note = {6th International Conference on Industry 4.0 and Smart Manufacturing},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2025.01.217},
url = {https://www.sciencedirect.com/science/article/pii/S187705092500225X},
author = {Silvia Colabianchi},
keywords = {chatbot, adaptive automation, industry 4.0, cybersecurity},
abstract = {The research proposes the application of Digital Intelligent Assistants (DIAs) as proactive agents that can support employees in dealing with cybersecurity issues in sustainable industrial processes underlying the importance of a fruitful Human-Artificial Intelligence collaboration. Cyber-attacks around the world are constantly increasing. DIAs are becoming more effective, also thanks to the use of Large Language Models. Users are required to recall security procedures and rules. Moreover, attacks are constantly evolving and following different patterns. The study presents how a DIA can be a backup agent during and after an attack. The application of digital intelligent assistance technology helps to reduce the cognitive load and pressure that users feel during downtime. In addition, the solution enhances attack reporting by decreasing the shame experienced by the victims. The research proposes a methodological design defining the agent’s technical and functional characteristics and its adaptive relationship with human characteristics. The solution is developed using the RASA framework and evaluated through a case study based on a phishing attack scenario.}
}
@article{KHEDDAR2023110851,
title = {Deep transfer learning for automatic speech recognition: Towards better generalization},
journal = {Knowledge-Based Systems},
volume = {277},
pages = {110851},
year = {2023},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2023.110851},
url = {https://www.sciencedirect.com/science/article/pii/S0950705123006019},
author = {Hamza Kheddar and Yassine Himeur and Somaya Al-Maadeed and Abbes Amira and Faycal Bensaali},
keywords = {Automatic speech recognition, Deep transfer learning, Fine-tuning, Domain adaptation, Models fusion, Large language model},
abstract = {Automatic speech recognition (ASR) has recently become an important challenge when using deep learning (DL). It requires large-scale training datasets and high computational and storage resources. Moreover, DL techniques and machine learning (ML) approaches in general, hypothesize that training and testing data come from the same domain, with the same input feature space and data distribution characteristics. This assumption, however, is not applicable in some real-world artificial intelligence (AI) applications. Moreover, there are situations where gathering real data is challenging, expensive, or rarely occurring, which cannot meet the data requirements of DL models. deep transfer learning (DTL) has been introduced to overcome these issues, which helps develop high-performing models using real datasets that are small or slightly different but related to the training data. This paper presents a comprehensive survey of DTL-based ASR frameworks to shed light on the latest developments and helps academics and professionals understand current challenges. Specifically, after presenting the DTL background, a well-designed taxonomy is adopted to inform the state-of-the-art. A critical analysis is then conducted to identify the limitations and advantages of each framework. Moving on, a comparative study is introduced to highlight the current challenges before deriving opportunities for future research.}
}
@article{MAXELOKOCHE20252508,
title = {AI adoption in crowdsourcing},
journal = {Procedia Computer Science},
volume = {253},
pages = {2508-2521},
year = {2025},
note = {6th International Conference on Industry 4.0 and Smart Manufacturing},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2025.01.311},
url = {https://www.sciencedirect.com/science/article/pii/S1877050925003199},
author = {John Michael {Maxel Okoche} and Marcia Mkansi and Godfrey Mugurusi and Wellington Chakuzira},
keywords = {Artificial Intelligence, Crowdsourcing, Crowdsourcing platforms, Systematic literature reviews},
abstract = {Despite significant technology advances especially in artificial intelligence (AI), crowdsourcing platforms still struggle with issues such as data overload and data quality problems, which hinder their full potential. This study addresses a critical gap in the literature how the integration of AI technologies in crowdsourcing could help overcome some these challenges. Using a systematic literature review of 77 journal papers, we identify the key limitations of current crowdsourcing platforms that included issues of quality control, scalability, bias, and privacy. Our research highlights how different forms of AI including from machine learning (ML), deep learning (DL), natural language processing (NLP), automatic speech recognition (ASR), and natural language generation techniques (NLG) can address the challenges most crowdsourcing platforms face. This paper offers knowledge to support the integration of AI first by identifying types of crowdsourcing applications, their challenges and the solutions AI offers for improvement of crowdsourcing.}
}
@article{FANANI2021721,
title = {Syllabification Model of Indonesian Language Named-Entity Using Syntactic n-Gram},
journal = {Procedia Computer Science},
volume = {179},
pages = {721-727},
year = {2021},
note = {5th International Conference on Computer Science and Computational Intelligence 2020},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2021.01.058},
url = {https://www.sciencedirect.com/science/article/pii/S1877050921000727},
author = {Ahmad Muammar Fanani and Suyanto Suyanto},
keywords = {syllabification, named-entities, syntactic n-gram},
abstract = {Syllabication or syllabification is an activity to detect syllable boundaries in a word. There are two main ways for automatic syllabification, namely rule-based and data-driven. The rule-based approach is based on the general principle of syllabification, while the data-driven method uses a set of syllabified words to create a syllabification of unknown words. Research on syllabification of words has been done a lot. However, most of these studies only deal with the formal words but still a few studies for named entities. Besides, named entities tend to be more complicated than the regular words. In this research, a syntactic n-Gram is proposed and investigated to syllabify the named entities since it is developed based on the n-gram that has an excellent accuracy and tends to be consistent with various languages. Evaluation on 20 k named-entities based on 4-fold cross-validation show that the proposed model gives a competitive syllable error rate (SER) compare to another similar n-gram-based model.}
}
@article{PALANIKUMAR2024108878,
title = {Multiple attribute decision-making model for artificially intelligent last-mile delivery robots selection in neutrosophic square root environment},
journal = {Engineering Applications of Artificial Intelligence},
volume = {136},
pages = {108878},
year = {2024},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2024.108878},
url = {https://www.sciencedirect.com/science/article/pii/S0952197624010364},
author = {Murugan Palanikumar and Chiranjibe Jana and Ibrahim M. Hezam and Abdelaziz Foul and Vladimir Simic and Dragan Pamucar},
keywords = {Square root neutrosophic sets, Euclidean distance, Hamming distance, Robotic intelligence, Multiple-attribute decision-making},
abstract = {We introduce novel methodological techniques for decision-making with multiple attributes utilizing logarithmic square root neutrosophic vague sets. One important thing is that we improved decision-making by adding logarithmic square root neutrosophic ambiguous weighted operators. Logarithmic square root, neutrosophic imprecise weighted averaging, geometric procedures, and expanded versions of these are some of the data processing methodologies that we explore. The use of Hamming distances and Euclidean distances in decision-making situations is illustrated by real-world instances. To clarify the basic properties of these sets, the research uses an algebraic framework. Numerous domains make use of neural networks, including translation, medical diagnosis, and picture and speech recognition. Developing multipurpose artificially intelligent robots with analytical, functional, visual, interactive, and textual capabilities relies heavily on the synergy between computer science and machine tool technology. This is especially true when it comes to the evolution of artificial intelligence. The operating procedures, expenses, time, and externalizes of an artificially intelligent robot system should be considered while assessing its quality. Finding the best answer from a list of possibilities is made easier with the help of expert views and established criteria. By comparing them to other methods, we verify and show that the suggested models work. The study’s findings highlight the importance of the research.}
}
@article{DIKMEN2025104251,
title = {Automated construction contract analysis for risk and responsibility assessment using natural language processing and machine learning},
journal = {Computers in Industry},
volume = {166},
pages = {104251},
year = {2025},
issn = {0166-3615},
doi = {https://doi.org/10.1016/j.compind.2025.104251},
url = {https://www.sciencedirect.com/science/article/pii/S0166361525000168},
author = {Irem Dikmen and Gorkem Eken and Huseyin Erol and M. Talat Birgonul},
keywords = {Automated contract review, Natural Language Processing (NLP), Machine Learning (ML), Artificial Intelligence (AI), Text classification, Construction risk management},
abstract = {Construction contracts contain critical risk-related information that requires in-depth examination, yet tight schedules for bidding limit the possibility of comprehensive review of extensive documents manually. This research aims to develop models for automating the review of construction contracts to extract information on risk and responsibility that will provide inputs for risk management plans. Models were trained on 2268 sentences from International Federation of Consulting Engineers templates and tested on an actual construction project contract containing 1217 sentences. A taxonomy classified sentences into Heading, Definition, Obligation, Risk, and Right categories with related parties of Contractor, Employer, and Shared. Twelve models employing diverse Natural Language Processing vectorization techniques and Machine Learning algorithms were implemented and benchmarked based on accuracy and F1 score. Binary classification of sentence types and an ensemble method integrating top models were further applied to improve performance. The best model achieved 89 % accuracy for sentence types and 83 % for related parties, demonstrating the capabilities of automated contract review for identification of risk and responsibilities. Adopting the proposed approach can significantly expedite contract reviews to support risk management activities, bid preparation processes and prevent disputes caused by overlooking risks and responsibilities.}
}
@article{RAHUL2023105051,
title = {Morphology & word sense disambiguation embedded multimodal neural machine translation system between Sanskrit and Malayalam},
journal = {Biomedical Signal Processing and Control},
volume = {85},
pages = {105051},
year = {2023},
issn = {1746-8094},
doi = {https://doi.org/10.1016/j.bspc.2023.105051},
url = {https://www.sciencedirect.com/science/article/pii/S1746809423004846},
author = {C. Rahul and T. Arathi and Lakshmi S. Panicker and R. Gopikakumari},
keywords = {Wavelet transform, Machine translation, Morphology, Feature vectors, Statistical},
abstract = {Machine translation is the process of conversion from one language to another using computers. In spite of the existence of several traditional machine translation systems like rule-based, statistical etc., the development of neural machine translation has significantly improved translation quality. However, the morphological richness and agglutinative nature of Indian languages hampers the usage of neural machine translation for translation among Indian languages despite its potential to overcome the difficulties posed by conventional translation systems. Hence the combination of neural machine translation with morphology, part of speech tagger and word sense disambiguation is proposed to address these challenges and adapt it for bidirectional translation between Sanskrit and Malayalam. Conventional neural machine translations are unimodal systems that utilize textual data for translation. Translation quality of conventional neural machine translation is enhanced with a novel multimodal bidirectional neural machine translation system with text & speech as the two modalities based on parallel text corpus and speech database. The best performance score is obtained for two level fusion, the feature vectors extracted from speech signals using different transforms (Wavelet transform, 1-D sequency mapped real transform & 1-D GCD based mapped real transform) are fused and which is further fused with a context vector from the text modality. Automatic and manual review methods are employed to assess quality of translation. Findings from the experiments reveal that addition of speech modality improved the overall quality of translation. BLEU scores of 43.89 and 42.72 are obtained for Sanskrit to Malayalam and Malayalam to Sanskrit multimodal translation respectively.}
}
@article{LI2025104767,
title = {Human intention recognition for trauma resuscitation: An interpretable deep learning approach for medical process data},
journal = {Journal of Biomedical Informatics},
volume = {161},
pages = {104767},
year = {2025},
issn = {1532-0464},
doi = {https://doi.org/10.1016/j.jbi.2024.104767},
url = {https://www.sciencedirect.com/science/article/pii/S1532046424001850},
author = {Keyi Li and Mary S. Kim and Wenjin Zhang and Sen Yang and Genevieve J. Sippel and Aleksandra Sarcevic and Randall S. Burd and Ivan Marsic},
keywords = {Predictive models, Process mining, Deep learning, Explainable AI, Decision support system, Trauma resuscitation},
abstract = {Objective
Trauma resuscitation is the initial evaluation and management of injured patients in the emergency department. This time-critical process requires the simultaneous pursuit of multiple resuscitation goals. Recognizing whether the required goal is being pursued can reduce errors in goal-related task performance and improve patient outcomes. The intention to pursue a goal can often be inferred from ongoing and completed treatment activities, but monitoring goal pursuit is cognitively demanding and prone to errors. We introduced an interpretable deep learning-based approach to aid decision making by automatically recognizing goal pursuit during trauma resuscitation.
Methods
We developed a predictive model to recognize the pursuit of two resuscitation goals: airway stabilization and circulatory support. We used event logs of 381 pediatric trauma resuscitations from August 2014 to November 2022 to train a neural network model with a dual-GRU structure that learns from both time-level and activity-type-level features. Our model makes predictions based on a sequence of activities and corresponding timestamps. To enhance the model and facilitate interpretation of predictions, we used the attention weights assigned by our model to represent the importance of features. These weights identified the critical time points and contributing activities during a goal pursuit.
Results
Our model achieved an average area under the receiver operating characteristic curve (AUC) score of 0.84 for recognizing airway stabilization and 0.83 for recognizing circulatory support. The most contributing activities and timestamps were aligned with domain knowledge.
Conclusion
Our interpretable predictive model can recognize provider intention based on a limited number of treatment activities. The model outperformed existing predictive models for medical events in accuracy and in interpretability. Integrating our model into a decision-support system would automate the tracking of provider actions, optimizing workflow to ensure timely delivery of care.}
}
@article{LI2024108407,
title = {A systematic review of digital transformation technologies in museum exhibition},
journal = {Computers in Human Behavior},
volume = {161},
pages = {108407},
year = {2024},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2024.108407},
url = {https://www.sciencedirect.com/science/article/pii/S0747563224002759},
author = {Jingjing Li and Xiaoyang Zheng and Ikumu Watanabe and Yoichi Ochiai},
keywords = {Digital transformation technologies, Museum exhibitions, Cultural heritage, Visitor experience, Technology and application scenario},
abstract = {Museum exhibitions, both temporary and permanent, form an essential link between a society and its cultural, historical, and artistic heritage sites. Curating artifacts and thematic displays in museum exhibitions can promote dialogue, foster cultural appreciation, and contribute to heritage preservation. The traditional way of holding museum exhibitions, heavily reliant on the expertise of designers and curatorial staff, makes them a labor-intensive process, from conceptualization to visitor engagement analysis. This review systematically compiles and examines how the application of digital transformation technologies (DTTs) has revolutionized museum exhibitions and augmented their future potential. DTTs such as artificial intelligence, immersive technologies, additive manufacturing, the Internet of Things, and cloud computing can help create engaging designs, improve accessibility and inclusivity, enhance educational potential, and allow for sophisticated visitor experience data collection and analyses, improving exhibit management. However, despite multiple specialized studies on DTTs and their roles in museum exhibitions, the connections between technology and application scenarios remain underexplored. By addressing this gap, this study is expected to inform and inspire practitioners in the museum and heritage sectors and present new research avenues for scholars.}
}
@article{LIPPITSCH2024107964,
title = {Development and evaluation of a software system for medical students to teach and practice anamnestic interviews with virtual patient avatars},
journal = {Computer Methods and Programs in Biomedicine},
volume = {244},
pages = {107964},
year = {2024},
issn = {0169-2607},
doi = {https://doi.org/10.1016/j.cmpb.2023.107964},
url = {https://www.sciencedirect.com/science/article/pii/S0169260723006302},
author = {Antonia Lippitsch and Jonas Steglich and Christiane Ludwig and Juliane Kellner and Linn Hempel and Dietrich Stoevesandt and Oliver Thews},
keywords = {Anamnestic interview, Medical students, Chatbot, Avatar, Practical exercise, Artificial intelligence},
abstract = {Background and Objectives
Taking a medical history is a core competence of the diagnostic process. At the beginning of their study medical students need to learn and practice the necessary techniques, initially focusing on good structuring and completeness. For this purpose, an interactive software system (ViPATalk) was developed in which the student can train to pose questions to virtual patient avatars in free conversation. At the end, the student receives feedback on the completeness of the questioning and an explanation of the essential items. The use of this software was compared to the traditional format of student role play in a randomized trial.
Methods
The central component of ViPATalk is a chatbot based on the AI language AIML, which generates an appropriate answer based on keywords in the student's question. To enable a realistic use, the student can enter the question via microphone (speech-to-text) and the answer generated by the chatbot is presented as a short video sequence, where the avatar is generated from a real image. Here, the transition between the sequences is seamless, resulting in a continuous movement of the avatar during the conversation.
Results
The learning success by practicing with ViPATalk was tested in an anamnestic interview with actors as simulated patients. The completeness of the conversation was evaluated with regard to numerous aspects and also certain behaviors during the conversation. These results were compared with those after practicing using peer role play.
Conclusions
It was found that practicing with ViPATalk was mostly equivalent to the students' role play. In the subsequent survey of the students, the wish was expressed that the ViPATalk software should also be used as an online tool for self-study and that there should be more cases for practicing.}
}
@article{SARIOGLU2025102423,
title = {Accessibility in conceptual modeling—A systematic literature review, a keyboard-only UML modeling tool, and a research roadmap},
journal = {Data & Knowledge Engineering},
volume = {158},
pages = {102423},
year = {2025},
issn = {0169-023X},
doi = {https://doi.org/10.1016/j.datak.2025.102423},
url = {https://www.sciencedirect.com/science/article/pii/S0169023X25000187},
author = {Aylin Sarioğlu and Haydar Metin and Dominik Bork},
keywords = {Conceptual modeling, Accessibility, Disability, Modeling tools, Systematic literature review, Tool review},
abstract = {The reports on Disability by the World Health Organization show that the number of people with disabilities is increasing. Consequently, accessibility should play an essential role in information systems engineering research. While there is an increasingly rich set of available web accessibility guidelines, testing frameworks, and generally accessibility features in modern web-based software systems, software development frameworks, and Integrated Development Environments, this paper shows, based on a systematic review of the literature and current modeling tools, that accessibility is, so far, only scarcely focused in conceptual modeling research. With this paper, we assess the state of the art of accessibility in conceptual modeling, we identify current research gaps, and we delineate a vision toward more accessible conceptual modeling methods and tools. As a concrete step forward toward this vision, we present a generic concept of a keyboard-only modeling tool interaction that is implemented as a new module for the Graphical Language Server Platform (GLSP) framework. We show—using a currently developed UML modeling tool—how efficiently this module allows GLSP-based tool developers to introduce accessibility features into their modeling tools, thereby engaging physically disabled users in conceptual modeling.}
}
@article{CHIURCO20253309,
title = {Leveraging Personal Assistants for Enhanced Access to Cultural Knowledge: A Case Study},
journal = {Procedia Computer Science},
volume = {253},
pages = {3309-3317},
year = {2025},
note = {6th International Conference on Industry 4.0 and Smart Manufacturing},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2025.02.055},
url = {https://www.sciencedirect.com/science/article/pii/S1877050925003989},
author = {Alessandro Chiurco and Virginia D’Augusta and Francesco Longo and Antonio Nervoso and Vittorio Solina and Simone Talarico},
keywords = {Artificial Intelligence (AI), Cultural Heritage, Virtual Assistants, Natural Language Processing (NLP)},
abstract = {This paper presents the development and implementation of the Tech4You personal assistant, an AI-driven tool designed to enhance accessibility and engagement within cultural heritage sites, particularly in historically underserved regions like Calabria. Leveraging natural language processing, machine learning, and a robust knowledge base, the assistant provides personalized, multilingual responses, accommodating a diverse spectrum of visitors regardless of language or physical abilities. Authors detail the methodological framework underpinning the assistant’s design, including the creation of a comprehensive Knowledge Base, system requirements, and a scalable architecture capable of handling high volumes of interactions. The assistant utilizes advanced technologies such as vector databases and semantic search to accurately interpret and respond to user queries. Preliminary functional tests conducted at sites like Timpone della Motta, Tiriolo, and Mileto demonstrate the assistant’s effectiveness in providing accurate and dynamic responses to varied user inquiries. By addressing accessibility challenges and fostering deeper connections to cultural history, it enhances visitor experiences and encourages inquisitive learning.}
}
@article{MAMUN2024108923,
title = {Smart reception: An artificial intelligence driven bangla language based receptionist system employing speech, speaker, and face recognition for automating reception services},
journal = {Engineering Applications of Artificial Intelligence},
volume = {136},
pages = {108923},
year = {2024},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2024.108923},
url = {https://www.sciencedirect.com/science/article/pii/S0952197624010819},
author = {Khondaker A. Mamun and Rahad Arman Nabid and Shehan Irteza Pranto and Saniyat Mushrat Lamim and Mohammad Masudur Rahman and Nabeel Mahammed and Mohammad Nurul Huda and Farhana Sarker and Rubaiya Rahtin Khan},
keywords = {Human-computer interaction, Automatic speech recognition, Natural language processing, Receptionist system, Artificial intelligence based systems},
abstract = {In recent times, service robots (SR) have become widely accepted in a variety of fields as an alternative to traditional reception methods. Artificial Intelligence (AI) driven systems are seen as efficient labor alternatives, resulting in several SR models already being developed, primarily designed for English-speaking environments. Despite a large Bangla-speaking population, the exploration and implementation of Bangla language support within AI reception systems remain unexplored due to limited resources, posing significant challenges for deployment. This study presents a novel AI-enabled receptionist framework tailored to Bangla-speaking environments, addressing the limitation of Bangla language resources for developing automated reception systems. Leveraging advanced AI technologies including Face Recognition, Speaker Recognition, Automatic Speech Recognition (ASR), Text-to-Speech Synthesis, and Question Answering System, our integrated system demonstrates promise to automate Bangla reception systems. Our suite of models yields positive performance, with a face recognition accuracy of 99.38%, a speaker recognition system with 5.83 Equal Error Rate (ERR), ASR model achieving a Word Error Rate (WER) of 9.005%, TTS model scoring a Mean Opinion Score (MOS) of 4.10, and a question-answering system with a validation loss of 0.03%. Real-world evaluation among 1664 users in a university setting achieved over 75% user satisfaction, with 88% expressing interest in real-life implementation, showcasing usability across different domains. Limitations such as limited training data, scalability, and environmental sensitivity persist, underscoring the need for further development. Nevertheless, our framework demonstrates potential for real-life implementation, fostering human-robot interaction in Bangla-speaking contexts and paving the way for future innovations in AI-driven Bangla receptionist systems.}
}
@article{RUKSAKULPIWAT2024,
title = {Assessing the Efficacy of ChatGPT Versus Human Researchers in Identifying Relevant Studies on mHealth Interventions for Improving Medication Adherence in Patients With Ischemic Stroke When Conducting Systematic Reviews: Comparative Analysis},
journal = {JMIR mHealth and uHealth},
volume = {12},
year = {2024},
issn = {2291-5222},
doi = {https://doi.org/10.2196/51526},
url = {https://www.sciencedirect.com/science/article/pii/S2291522224000809},
author = {Suebsarn Ruksakulpiwat and Lalipat Phianhasin and Chitchanok Benjasirisan and Kedong Ding and Anuoluwapo Ajibade and Ayanesh Kumar and Cassie Stewart},
keywords = {ChatGPT, systematic reviews, medication adherence, mobile health, mHealth, ischemic stroke, mobile phone},
abstract = {Background
ChatGPT by OpenAI emerged as a potential tool for researchers, aiding in various aspects of research. One such application was the identification of relevant studies in systematic reviews. However, a comprehensive comparison of the efficacy of relevant study identification between human researchers and ChatGPT has not been conducted.
Objective
This study aims to compare the efficacy of ChatGPT and human researchers in identifying relevant studies on medication adherence improvement using mobile health interventions in patients with ischemic stroke during systematic reviews.
Methods
This study used the PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analyses) guidelines. Four electronic databases, including CINAHL Plus with Full Text, Web of Science, PubMed, and MEDLINE, were searched to identify articles published from inception until 2023 using search terms based on MeSH (Medical Subject Headings) terms generated by human researchers versus ChatGPT. The authors independently screened the titles, abstracts, and full text of the studies identified through separate searches conducted by human researchers and ChatGPT. The comparison encompassed several aspects, including the ability to retrieve relevant studies, accuracy, efficiency, limitations, and challenges associated with each method.
Results
A total of 6 articles identified through search terms generated by human researchers were included in the final analysis, of which 4 (67%) reported improvements in medication adherence after the intervention. However, 33% (2/6) of the included studies did not clearly state whether medication adherence improved after the intervention. A total of 10 studies were included based on search terms generated by ChatGPT, of which 6 (60%) overlapped with studies identified by human researchers. Regarding the impact of mobile health interventions on medication adherence, most included studies (8/10, 80%) based on search terms generated by ChatGPT reported improvements in medication adherence after the intervention. However, 20% (2/10) of the studies did not clearly state whether medication adherence improved after the intervention. The precision in accurately identifying relevant studies was higher in human researchers (0.86) than in ChatGPT (0.77). This is consistent with the percentage of relevance, where human researchers (9.8%) demonstrated a higher percentage of relevance than ChatGPT (3%). However, when considering the time required for both humans and ChatGPT to identify relevant studies, ChatGPT substantially outperformed human researchers as it took less time to identify relevant studies.
Conclusions
Our comparative analysis highlighted the strengths and limitations of both approaches. Ultimately, the choice between human researchers and ChatGPT depends on the specific requirements and objectives of each review, but the collaborative synergy of both approaches holds the potential to advance evidence-based research and decision-making in the health care field.}
}
@article{HERATH2022100076,
title = {Adoption of artificial intelligence in smart cities: A comprehensive review},
journal = {International Journal of Information Management Data Insights},
volume = {2},
number = {1},
pages = {100076},
year = {2022},
issn = {2667-0968},
doi = {https://doi.org/10.1016/j.jjimei.2022.100076},
url = {https://www.sciencedirect.com/science/article/pii/S2667096822000192},
author = {H.M.K.K.M.B. Herath and Mamta Mittal},
keywords = {Artificial intelligence (AI), Digital cities, Intelligent interaction, Internet of Things (IoT), Smart cities},
abstract = {Recently, the population density in cities has increased at a higher pace. According to the United Nations Population Fund, cities accommodated 3.3 billion people (54%) of the global population in 2014. By 2050, around 5 billion people (68%) will be residing in cities. In order to make lifestyles in cities more comfortable and cost-effective, the city must be smart and intelligent. It is mainly accomplished through an intelligent decision-making process using computational intelligence-based technologies. This paper explored how artificial intelligence (AI) is being used in the smart city concept. From 2014 to 2021, we examined 133 articles (97% of Scopus and 73% of WoS) in healthcare, education, environment and waste management, agriculture, mobility and smart transportation, risk management, and security. Moreover, we observed that the healthcare (23% impact), mobility (19% impact), privacy and security (11% impact), and energy sectors (10% impact) have a more significant influence on AI adoption in smart cities. Since the epidemic hit cities in 2019, the healthcare industry has intensified its AI-based advances by 60%. According to the analysis, AI algorithms such as ANN, RNN/LSTM, CNN/R-CNN, DNN, and SVM/LS-SVM have a higher impact on the various smart city domains.}
}
@article{HACKER2023105871,
title = {The European AI liability directives – Critique of a half-hearted approach and lessons for the future},
journal = {Computer Law & Security Review},
volume = {51},
pages = {105871},
year = {2023},
issn = {2212-473X},
doi = {https://doi.org/10.1016/j.clsr.2023.105871},
url = {https://www.sciencedirect.com/science/article/pii/S026736492300081X},
author = {Philipp Hacker},
keywords = {Artificial intelligence, ChatGPT, Product liability, EU law, AI act, Sustainability, Innovation, Large generative AI models},
abstract = {The optimal liability framework for AI systems remains an unsolved problem across the globe. With ChatGPT and other large generative models taking the technology to the next level, solutions are urgently needed. In a much-anticipated move, the European Commission advanced two proposals outlining the European approach to AI liability in September 2022: a novel AI Liability Directive (AILD) and a revision of the Product Liability Directive (PLD). They constitute the final cornerstone of AI regulation in the EU. Crucially, the liability proposals and the proposed EU AI Act are inherently intertwined: the latter does not contain any individual rights of affected persons, and the former lack specific, substantive rules on AI development and deployment. Taken together, these acts may well trigger a “Brussels effect” in AI regulation, with significant consequences for the US and other countries. Against this background, this paper makes three novel contributions. First, it examines in detail the liability proposals and shows that, while making steps in the right direction, they ultimately represent a half-hearted approach: if enacted as foreseen, AI liability in the EU will primarily rest on disclosure of evidence mechanisms and a set of narrowly defined presumptions concerning fault, defectiveness and causality. Hence, second, the article suggests amendments to the proposed AI liability framework. They are collected in a concise Annex at the end of the paper. I argue, inter alia, that the dichotomy between the fault-based AILD Proposal and the supposedly strict liability PLD Proposal is fictional and should be abandoned; that an EU framework for AI liability should comprise one fully harmonizing regulation instead of two insufficiently coordinated directives; and that the current proposals unjustifiably collapse fundamental distinctions between social and individual risk by equating high-risk AI systems in the AI Act with those under the liability framework. Third, based on an analysis of the key risks AI poses, the final part of the paper maps out a road for the future of AI liability and regulation, in the EU and beyond. More specifically, I make four key proposals. Effective compensation should be ensured by combining truly strict liability for certain high-risk AI systems with general presumptions of defectiveness, fault and causality in cases involving SMEs or non-high-risk AI systems. The paper introduces a novel distinction between illegitimate- and legitimate-harm models to delineate strict liability's scope. Truly strict liability should be reserved for high-risk AI systems that, from a social perspective, should not cause harm (illegitimate-harm models, e.g., autonomous vehicles or medical AI). Models meant to cause some unavoidable harm by ranking and rejecting individuals (legitimate-harm models, e.g., credit scoring or insurance scoring) may merely face rebuttable presumptions of defectiveness and causality. General-purpose AI systems and Foundation Models should only be subjected to high-risk regulation, including liability for high-risk AI systems, in specific high-risk use cases for which they are deployed. Consumers, in turn, ought to be liable based on regular fault, in general. Furthermore, innovation and legal certainty should be fostered through a comprehensive regime of safe harbours, defined quantitatively to the best extent possible. Moreover, trustworthy AI remains an important goal for AI regulation. Hence, the liability framework must specifically extend to non-discrimination cases and provide for clear rules concerning explainability (XAI). Finally, awareness for the climate effects of AI, and digital technology more broadly, is rapidly growing in computer science. In diametrical opposition to this shift in discourse and understanding, however, EU legislators have long neglected environmental sustainability in both the draft AI Act and the proposed liability regime. To counter this, I propose to jump-start sustainable AI regulation via sustainability impact assessments in the AI Act and sustainable design defects in the liability regime. In this way, the law may help spur not only fair AI and XAI, but also sustainable AI (SAI).}
}
@article{AFFANDI202419,
title = {An Artificial Intelligence-based Application for Recognizing and Identifying Aerial Objects based on Voice Input},
journal = {Procedia Computer Science},
volume = {234},
pages = {19-27},
year = {2024},
note = {Seventh Information Systems International Conference (ISICO 2023)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.02.148},
url = {https://www.sciencedirect.com/science/article/pii/S187705092400334X},
author = {Luqman Affandi and Arwin Datumaya Wahyudi Sumari and  Abdulloh and Rokhimatul Wakhidah and Inayati Machsus Izza Addin and Muhammad Auful Kirom},
keywords = {Artificial Intelligence, Ground-to-Air observation, machine learning, Naïve Bayes Classifier, object recognition and identification, UAA, voice recognition},
abstract = {Visual observation to recognize and identify aerial objects is a means to protect air sovereignty, and the delay can endanger it. Visual observation can be done through Ground-to-Air (GTA) or by approaching through Air-to-Air (ATA) using binoculars. The observation needs accuracy and speed to speed up the decision-making process. We propose an Artificial Intelligence (AI) system that receives voice input to recognize and identify an Unmanned Aerial Aircraft (UAA). We employed Naïve Bayes Classifier (NBC) that processes inputs from voice-to-text tools containing the observed UAA's feature. With 70 UAA samples, the AI system achieved an accuracy of 79% and a WER of 4.16%.}
}
@article{ALQARALLEH20223913,
title = {Automated Handwriting Recognition and Speech Synthesizer for Indigenous Language Processing},
journal = {Computers, Materials and Continua},
volume = {72},
number = {2},
pages = {3913-3927},
year = {2022},
issn = {1546-2218},
doi = {https://doi.org/10.32604/cmc.2022.026531},
url = {https://www.sciencedirect.com/science/article/pii/S1546221822014461},
author = {Bassam A. Y. Alqaralleh and Fahad Aldhaban and Feras Mohammed A-Matarneh and Esam A. AlQaralleh},
keywords = {Computational linguistics, handwriting character recognition, natural language processing, indigenous language},
abstract = {In recent years, researchers in handwriting recognition analysis relating to indigenous languages have gained significant internet among research communities. The recent developments of artificial intelligence (AI), natural language processing (NLP), and computational linguistics (CL) find useful in the analysis of regional low resource languages. Automatic lexical task participation might be elaborated to various applications in the NLP. It is apparent from the availability of effective machine recognition models and open access handwritten databases. Arabic language is a commonly spoken Semitic language, and it is written with the cursive Arabic alphabet from right to left. Arabic handwritten Character Recognition (HCR) is a crucial process in optical character recognition. In this view, this paper presents effective Computational linguistics with Deep Learning based Handwriting Recognition and Speech Synthesizer (CLDL-THRSS) for Indigenous Language. The presented CLDL-THRSS model involves two stages of operations namely automated handwriting recognition and speech recognition. Firstly, the automated handwriting recognition procedure involves preprocessing, segmentation, feature extraction, and classification. Also, the Capsule Network (CapsNet) based feature extractor is employed for the recognition of handwritten Arabic characters. For optimal hyperparameter tuning, the cuckoo search (CS) optimization technique was included to tune the parameters of the CapsNet method. Besides, deep neural network with hidden Markov model (DNN-HMM) model is employed for the automatic speech synthesizer. To validate the effective performance of the proposed CLDL-THRSS model, a detailed experimental validation process takes place and investigates the outcomes interms of different measures. The experimental outcomes denoted that the CLDL-THRSS technique has demonstrated the compared methods.}
}
@article{KULIGOWSKA20231134,
title = {Challenges of Automatic Speech Recognition for medical interviews - research for Polish language},
journal = {Procedia Computer Science},
volume = {225},
pages = {1134-1141},
year = {2023},
note = {27th International Conference on Knowledge Based and Intelligent Information and Engineering Sytems (KES 2023)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2023.10.101},
url = {https://www.sciencedirect.com/science/article/pii/S1877050923012590},
author = {Karolina Kuligowska and Maciej Stanusch and Marek Koniew},
keywords = {automatic speech recognition, speech-to-text, Polish speech recognition system, medical interview transcript},
abstract = {Automatic Speech Recognition (ASR) systems are quickly becoming a crucial element in supporting healthcare providers, improving the flow of information among medical teams, and enhancing the patient's experience. However, to be fully supportive, these ASR systems must meet certain requirements dictated by market realities: high accuracy of speech recognition and low rate of errors, the possibility of additional training the model, and the possibility of on-premise system installation. Therefore, the aim of this paper is to perform a comparative analysis of leading ASR systems available on the Polish market for the needs of conducting medical interviews. We selected three systems, Google ASR, Microsoft ASR, and Techmo ASR, and we compared their performance on a prepared data set of medical-related expressions spoken in Polish. The results of our analysis indicated that there are minor discrepancies in the accuracy of speech recognition between all three evaluated ASR systems, whereas only two ASR systems met the raised requirements, in both cases partially. Still, they all exhibited specific problems in recognising word endings or word boundaries. We were able to categorise such problems into: Misrecognitions, Quality Problems, and Word Boundaries, varying in their level of influence on the further speech recognition process. Our research findings are expected to provide valuable insights to a wide range of stakeholders facilitating the development of tailored speech recognition solutions that meet the specific needs of medical sector.}
}
@article{LEI2025200224,
title = {Research on Automatic Processing System of Financial Information in Colleges and Universities Based on NLP-KG Fusion Algorithm},
journal = {Systems and Soft Computing},
pages = {200224},
year = {2025},
issn = {2772-9419},
doi = {https://doi.org/10.1016/j.sasc.2025.200224},
url = {https://www.sciencedirect.com/science/article/pii/S2772941925000420},
author = {Jin Lei and Mengke Wei and Yiwen She and Weixia Wang},
keywords = {Natural language processing, Knowledge graph, University finance, Automated processing, Risk warning},
abstract = {At a time when information technology is deeply embedded in the management of colleges and universities and the automatic demand for financial information processing is urgent, the automatic processing system of financial information in colleges and universities based on NLP and KG fusion algorithm has come into being, which can efficiently process massive data, improve work efficiency an scientific decision-making, but its data security and privacy protection are extremely critical. Traditional financial information processing in colleges and universities relies on manual entry and review, which is inefficient, error-prone and scattered, and early automation tools have problems such as insufficient semantic understanding and correlation analysis, and data silos. Financial data involves sensitive information such as fund receipts and expenditures, faculty and staff salaries, and student tuition, and relevant national laws and regulations also put forward strict requirements for its security and privacy protection. The existing mechanisms ensure security and privacy from multiple aspects: access control (using multi-factor identity authentication and role-based permission management), data encryption (SSL/TLS encryption protocol and AES algorithms are used for transmission and storage, respectively), data backup and recovery (regular backup, off-site storage, and recovery drills), audit and monitoring (detailed recording of operations and real-time monitoring of network traffic, etc.). The NLP-KG fusion algorithm further improves the system's data security and privacy protection capabilities through data semantic understanding to identify potential risks, intelligently adjust access permissions, and realize intelligent retrieval and analysis of encrypted data. In short, while the system brings opportunities, universities need to continuously improve data security and privacy protection mechanisms to cope with the complex cybersecurity environment and financial management needs.}
}
@article{VESCAN2025110032,
title = {Software maintainability prediction based on change metric using neural network models},
journal = {Engineering Applications of Artificial Intelligence},
volume = {144},
pages = {110032},
year = {2025},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2025.110032},
url = {https://www.sciencedirect.com/science/article/pii/S0952197625000326},
author = {Andreea Vescan and Daniel Barac-Antonescu},
keywords = {Neural network models, Maintainability, Prediction, Implemented artificial intelligence, Application of artificial intelligence},
abstract = {The increased software system complexity requires better approaches to advise developers in the process of changing parts of the software during the maintenance and evolution process. The aim of this paper is twofold: (1) to provide an in-depth analysis and comparison of various existing and newly developed maintainability prediction models, and (2) to investigate and obtain the best set of metrics for software maintainability prediction. Various code metrics were employed to explore and discover the best model, three previously developed configuration metrics as dependent variables, i.e. with 10 metrics, 2 metrics, and 3 metrics. The new proposed model considers the correlation between code metrics and the maintenance change metric (four and five metrics were considered in the two used projects). The overall framework of our Neural Network Change Prediction (NNCP) approach uses an artificial neural network algorithm with various input layers. Different validation methods were employed: k-fold cross-validation and hold-out validation. Statistical analysis performed using the Wilcoxon signed rank test between the four models shows that the new proposed model can better predict the maintainability change metric, having one metric in common with the compared model but considering other three distinct ones.}
}
@article{MEHRISH2023101869,
title = {A review of deep learning techniques for speech processing},
journal = {Information Fusion},
volume = {99},
pages = {101869},
year = {2023},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2023.101869},
url = {https://www.sciencedirect.com/science/article/pii/S1566253523001859},
author = {Ambuj Mehrish and Navonil Majumder and Rishabh Bharadwaj and Rada Mihalcea and Soujanya Poria},
keywords = {Deep learning, Speech processing, Transformers, Survey, Trends},
abstract = {The field of speech processing has undergone a transformative shift with the advent of deep learning. The use of multiple processing layers has enabled the creation of models capable of extracting intricate features from speech data. This development has paved the way for unparalleled advancements in speech recognition, text-to-speech synthesis, automatic speech recognition, and emotion recognition, propelling the performance of these tasks to unprecedented heights. The power of deep learning techniques has opened up new avenues for research and innovation in the field of speech processing, with far-reaching implications for a range of industries and applications. This review paper provides a comprehensive overview of the key deep learning models and their applications in speech-processing tasks. We begin by tracing the evolution of speech processing research, from early approaches, such as MFCC and HMM, to more recent advances in deep learning architectures, such as CNNs, RNNs, transformers, conformers, and diffusion models. We categorize the approaches and compare their strengths and weaknesses for solving speech-processing tasks. Furthermore, we extensively cover various speech-processing tasks, datasets, and benchmarks used in the literature and describe how different deep-learning networks have been utilized to tackle these tasks. Additionally, we discuss the challenges and future directions of deep learning in speech processing, including the need for more parameter-efficient, interpretable models and the potential of deep learning for multimodal speech processing. By examining the field’s evolution, comparing and contrasting different approaches, and highlighting future directions and challenges, we hope to inspire further research in this exciting and rapidly advancing field.}
}
@article{JO2022768,
title = {Impact of Information Security on Continuance Intention of Artificial Intelligence Assistant},
journal = {Procedia Computer Science},
volume = {204},
pages = {768-774},
year = {2022},
note = {International Conference on Industry Sciences and Computer Science Innovation},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2022.08.093},
url = {https://www.sciencedirect.com/science/article/pii/S1877050922008316},
author = {Hyeon Jo},
keywords = {Artificial Intelligence Assistant, Virtual Assistant, Personal Voice Assistant, Industry 4.0},
abstract = {With the development of the 4th Industrial Revolution, interest in artificial intelligence (AI) has also increased. People use useful functions or conduct conversations through AI assistants (AIA). In using AIA, information security factors are important because interaction with AIAs exchanges personal information. In this context, this study aims to investigate the determinants of continuance intention in the domain of AIA. This study empirically analyzed of 250 users using AIA. Partial least squares structural equation modeling (PLS-SEM) was performed to test hypotheses. The results revealed that trust and privacy concerns on surroundings are the major antecedents of continuance intention. The results of this study will provide meaningful guidelines for the AI industry.}
}
@article{YU2024103720,
title = {An explainable deepfake of speech detection method with spectrograms and waveforms},
journal = {Journal of Information Security and Applications},
volume = {81},
pages = {103720},
year = {2024},
issn = {2214-2126},
doi = {https://doi.org/10.1016/j.jisa.2024.103720},
url = {https://www.sciencedirect.com/science/article/pii/S2214212624000231},
author = {Ning Yu and Long Chen and Tao Leng and Zigang Chen and Xiaoyin Yi},
keywords = {Explainable artificial intelligence, SHAP, Spoofed speech detection, Feature splice},
abstract = {Research on deepfake techniques for speech is crucial for combatting the spread of fake information, safeguarding public privacy, and advancing forensic techniques. However, the lack of transparency and explainability of spoofed speech detection models raises concerns about their reliability. In this paper, we suggest using raw waveform signals and spectrograms as fused features of the spoofed speech detection model. We use the SHAP method to analyze the feature distribution of spoofed speech detection and explain the likelihood of fake speech. Our experimental results demonstrate that our approach achieves better classification results with lighter model parameters than other feature fusion methods. Finally, the feature contribution values are calculated under the SHAP method to visualize them as heat maps. It helps researchers to analyze the feature distribution of spoofed speech to identify the most critical features that distinguish between spoofed and bona fide and to ensure transparency in their use.}
}
@article{BENDIAB2025103935,
title = {Deepfakes in digital media forensics: Generation, AI-based detection and challenges},
journal = {Journal of Information Security and Applications},
volume = {88},
pages = {103935},
year = {2025},
issn = {2214-2126},
doi = {https://doi.org/10.1016/j.jisa.2024.103935},
url = {https://www.sciencedirect.com/science/article/pii/S2214212624002370},
author = {Gueltoum Bendiab and Houda Haiouni and Isidoros Moulas and Stavros Shiaeles},
keywords = {Deepfake, Artificial intelligence, Digital media forensics, Security, Deepfake detection},
abstract = {Deepfake technology presents significant challenges for digital media forensics. As deepfakes become increasingly sophisticated, the ability to detect and attribute manipulated media becomes more difficult. The main challenge lies in the realistic and convincing nature of deepfakes, which can deceive human perception and traditional forensic techniques. Furthermore, the widespread availability of open-source deepfake tools and increasing computational power contribute to the ease with which malicious actors can create and disseminate deepfakes. The challenges posed by deepfakes for digital media forensics are multifaceted. Therefore, the development of sophisticated detection algorithms, the creation of comprehensive datasets, and the establishment of legal frameworks are crucial in addressing these challenges. This paper provides a comprehensive analysis of current methods for deepfake generation and the issues surrounding their detection. It also explores the potential of modern AI-based detection techniques in combating the proliferation of deepfakes. This analysis aims to contribute to advancing deepfake detection by highlighting the limits of current detection techniques, the most relevant issues, the upcoming challenges, and suggesting future directions for research.}
}
@article{DONGBO2023103440,
title = {Intelligent chatbot interaction system capable for sentimental analysis using hybrid machine learning algorithms},
journal = {Information Processing & Management},
volume = {60},
number = {5},
pages = {103440},
year = {2023},
issn = {0306-4573},
doi = {https://doi.org/10.1016/j.ipm.2023.103440},
url = {https://www.sciencedirect.com/science/article/pii/S0306457323001772},
author = {Ma Dongbo and Sami Miniaoui and Li Fen and Sara A. Althubiti and Theyab R Alsenani},
keywords = {Chatbot, NLP, AI, Artificial intelligence markup language, Fuzzy naïve Bayes classifier, Bi-directional recurrent neural network},
abstract = {Chatbots actively help the human user through digital conversation through NLP based on artificial intelligence (AI). It can be pre-trained to understand the user's queries and produce an immediate response in NLP. The user input of the chatbot is any format like voice, text, sentiments, etc. Many research works have been implemented. The issues of existing works are that during the digital conversation, it does not accurately identify the user's requirement, it may go irrelevant to the user's query, and also, primarily, it is voice-based and faces hitches in the analysis of the user's intention, unable to track the context in long-conversation. Therefore, for understanding the context, sentimental calculations are essential. This paper proposed to make the immediate response of users in the chatbot by using Bi-directional Recurrent Neural Network with a Fuzzy Naïve Bayes classifier (BRNN-FNB). This paper aims to build chatbot models with AI-based sentimental analysis, which helps humans to perform accurate interactions. The working concept of chatbots is based on two forms of artificial intelligence domains: machine learning and natural language processing. It may be used in many applications like digital marketing, education, and online forums. The accuracy rate of the proposed work BRNN-FNB got 93% using the Seq-to-Seq technique. And also, the accuracy rate of the proposed work BRNN-FNB without using Seq-to-Seq got 92%.}
}
@article{CHU2024105686,
title = {Calculating the distance between languages with deep learning},
journal = {Biomedical Signal Processing and Control},
volume = {88},
pages = {105686},
year = {2024},
issn = {1746-8094},
doi = {https://doi.org/10.1016/j.bspc.2023.105686},
url = {https://www.sciencedirect.com/science/article/pii/S1746809423011199},
author = {Man-ni Chu and Ming-lei Yu and Jia-lien Hsu},
keywords = {Accent similarity, Deep learning, Siamese network},
abstract = {Artificial intelligence (AI) has been implemented in various fields, including speech recognition. In this paper, a computational method is proposed for calculating the similarity between different languages or language varieties, with their similarity represented in terms of distance. In this process, we extracted mel spectrogram features from speech signals to provide the feature vectors and derived pairs of signal tokens based on vectors. Then, we trained a Siamese time-delay neural network to calculate the distance between two signal tokens. If the token pairs are from the same language group, the distance obtained using this Siamese network model is zero. In this preliminary experiment, three types of regional Mandarin Chinese (BJ, FJ, GD) were used as the dataset. The results gave the F1-score of 0.794, 0.623, and 0.715 for the classification task with respect to BJ, FJ, and GD dataset. In addition, 10 Taiwan Mandarin (TM) native speakers participated in identification and a pair-wise discrimination experiment to allow comparison with the Siamese network model. The 10 TM natives tended to misidentify GD-accented Mandarin as FJ-accented Mandarin resulting in a much greater distance between the two in the FJ-GD discrimination task compared to the Siamese network model. Overall, the results show that the performance of our model is better than the comparative experiment in completing the identification task, with the distance between the Siamese network model and the experiment having a mean absolute error (MAE) of 0.35. The familiarity might be the reason why the 10 TM natives displayed a bias towards BJ-accented Mandarin Chinese. To sum up, we provide a computational method to calculate the distance between two languages or language varieties, which can help linguists pre-classify sound files.}
}
@article{YANG2023533,
title = {Intelligent English Translation Model Based on Improved GLR Algorithm},
journal = {Procedia Computer Science},
volume = {228},
pages = {533-542},
year = {2023},
note = {3rd International Conference on Machine Learning and Big Data Analytics for IoT Security and Privacy},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2023.11.061},
url = {https://www.sciencedirect.com/science/article/pii/S1877050923018859},
author = {Shengbo Yang},
keywords = {Improved GLR algorithm, English translation, Intelligent recognition, Model building, Computer image processing},
abstract = {An intelligent English translation model based on the improved GLR algorithm is proposed to solve the imprecise problem of traditional methods. This algorithm is used to create a body of tagged sentences from tens of thousands of English and Chinese words, so that the sentences can be searched. In addition, the knowledge structure translated into English is designed to prepare the knowledge structure based on information collection, processing and production. To use the knowledge of English translation, the English text is written according to the plan, design and negative features are extracted. The clinical trial was based on the standard knowledge of English translation and the trial data was recorded. According to the test results, the accuracy of English translation is 75.1% before modification and 99.1% after using smart text. Syntax and sentence-based knowledge systems have weak nodal point distributions, but the nodal point distributions are compact in the first, fourth, and fifth trials. Conclusion: The English translation knowledge model is highly accurate and can meet the needs of English translation.}
}
@article{EFANOV2022415,
title = {The BiLSTM-based synthesized speech recognition},
journal = {Procedia Computer Science},
volume = {213},
pages = {415-421},
year = {2022},
note = {2022 Annual International Conference on Brain-Inspired Cognitive Architectures for Artificial Intelligence: The 13th Annual Meeting of the BICA Society},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2022.11.086},
url = {https://www.sciencedirect.com/science/article/pii/S187705092201777X},
author = {Dmitry Efanov and Pavel Aleksandrov and Nikolay Karapetyants},
keywords = {synthesized speech, deepfake voice, voice cloning, LSTM},
abstract = {Homer Dudley's VODER is considered the first attempt to synthesize human speech electronically by breaking it down into acoustic components. Fifty years later, Terminator 2 featured an example of human speech synthesized with artificial intelligence that was used to deceive a human. Speech synthesis is the artificial simulation of human speech using a computer or other device. The counterpart of the voice recognition, speech synthesis is mainly used to convert textual information into audio information so that a person can naturally interact with digital devices. For example, it is used in assistive technology to help visually impaired people read textual content. A separate direction is the use of speech synthesis to create a clone of a person's voice. Deepfake voice technology, also called voice cloning, has advanced to the point where it can accurately reproduce the human voice by mimicking intonation and other features of the speaker. And it can be used to harm a person. Attackers can employ it to fool voice authentication systems or create fake audio recordings to defame public figures, or combine voice clone with social engineering techniques to bamboozle people. This article discusses the architecture of a voice recognition system that will significantly reduce the possibility of fraud using deepfake voice.}
}
@article{COLABIANCHI2023100510,
title = {Human-technology integration with industrial conversational agents: A conceptual architecture and a taxonomy for manufacturing},
journal = {Journal of Industrial Information Integration},
volume = {35},
pages = {100510},
year = {2023},
issn = {2452-414X},
doi = {https://doi.org/10.1016/j.jii.2023.100510},
url = {https://www.sciencedirect.com/science/article/pii/S2452414X23000833},
author = {Silvia Colabianchi and Andrea Tedeschi and Francesco Costantino},
keywords = {Chatbot, Natural language processing, Dialog systems, Voice bot, Large language model},
abstract = {Conversational agents are systems with great potential to enhance human-computer interaction in industrial settings. Although the number of applications of conversational agents in many fields is growing, there is no shared view of the elements to design and implement for chatbots in the industrial field. The paper presents the combination of many research contributions into an integrated conceptual architecture, for developing industrial conversational agents using Nickerson's methodology. The conceptual architecture consists of five core modules; every module consists of specific elements and approaches. Furthermore, the paper defines a taxonomy from the study of empirical applications of manufacturing conversational agents. Indeed, some applications of chatbots in manufacturing are available but those have never been collected in single research. The paper fills this gap by analyzing the empirical cases and presenting a qualitative analysis, with verification of the proposed taxonomy. The contribution of the article is mainly to illustrate the elements needed for the development of a conversational agent in manufacturing: researchers and practitioners can use the proposed conceptual architecture and taxonomy to more easily investigate, define, and develop all the elements for chatbot implementation.}
}
@article{OUNI20241355,
title = {Deep learning-based Soft word embedding approach for sentiment analysis},
journal = {Procedia Computer Science},
volume = {246},
pages = {1355-1364},
year = {2024},
note = {28th International Conference on Knowledge Based and Intelligent information and Engineering Systems (KES 2024)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.09.720},
url = {https://www.sciencedirect.com/science/article/pii/S1877050924027893},
author = {Chafika Ouni and Emna Benmohamed and Hela Ltifi},
keywords = {Sentiment analysis, word embedding, Deep learning, Word2vec, Glove, SoftEMD, Soft-Voting},
abstract = {Word Embeddings (WE) play a crucial role in capturing the meanings of words. They provide continuous vector representations that encode semantic and syntactic information. To accurately convert words into meaningful vectors, in this paper, we propose a novel approach called Soft EMBedding method (SoftEMB). SoftEMB combines the strengths of the Glove and Word2Vec methods through a Soft-Voting algorithm. The SoftEMD approach aims to improve the performance of word embedding, particularly in the context of Sentiment Analysis (SA) hybrid models. To evaluate the SoftEMD performance, we test it on various SA models based on CNN-LSTM, CNN-GRU, CNN-biLSTM, and CNN-bi-GRU. Our results demonstrate a substantial enhancement in accuracy when evaluating movie reviews, with scores of 88.29%, 88.33%, 88.27%, and 88.27%. Similarly, for Sentiment140 dataset, our proposal shows improved results, achieving accuracy rates of 83.27%, 82.78%, 82.76%, and 82.51%. These results highlight the significant progress made in accurately analyzing both movie reviews and the Sentiment140 dataset.}
}
@article{COLABIANCHI2024104129,
title = {Assessment of a large language model based digital intelligent assistant in assembly manufacturing},
journal = {Computers in Industry},
volume = {162},
pages = {104129},
year = {2024},
issn = {0166-3615},
doi = {https://doi.org/10.1016/j.compind.2024.104129},
url = {https://www.sciencedirect.com/science/article/pii/S0166361524000575},
author = {Silvia Colabianchi and Francesco Costantino and Nicolò Sabetta},
keywords = {Chatbot, Experimental design, Artificial intelligence, Natural language processing, Industry 4.0, Industry 5.0},
abstract = {The use of Digital Intelligent Assistants (DIAs) in manufacturing aims to enhance performance and reduce cognitive workload. By leveraging the advanced capabilities of Large Language Models (LLMs), the research aims to understand the impact of DIAs on assembly processes, emphasizing human-centric design and operational efficiency. The study is novel in considering the three primary objectives: evaluating the technical robustness of DIAs, assessing their effect on operators' cognitive workload and user experience, and determining the overall performance improvement of the assembly process. Methodologically, the research employs a laboratory experiment, incorporating a controlled setting to meticulously assess the DIA's performance. The experiment used a between-subjects design comparing a group of participants using the DIA against a control group relying on traditional manual methods across a series of assembly tasks. Findings reveal a significant enhancement in the operators' experience, a reduction in cognitive load, and an improvement in the quality of process outputs when the DIA is employed. The article contributes to the study of the DIA's potential and AI integration in manufacturing, offering insights into the design, development, and evaluation of DIAs in industrial settings.}
}
@article{KAMAL20225547,
title = {An Innovative Approach Utilizing Binary-View Transformer for Speech Recognition Task},
journal = {Computers, Materials and Continua},
volume = {72},
number = {3},
pages = {5547-5562},
year = {2022},
issn = {1546-2218},
doi = {https://doi.org/10.32604/cmc.2022.024590},
url = {https://www.sciencedirect.com/science/article/pii/S1546221822009328},
author = {Muhammad Babar Kamal and Arfat Ahmad Khan and Faizan Ahmed Khan and Malik Muhammad {Ali Shahid} and Chitapong Wechtaisong and Muhammad Daud Kamal and Muhammad Junaid Ali and Peerapong Uthansakul},
keywords = {Convolution neural network, multi-head attention, multi-view, RNN, self-attention, speech recognition, transformer},
abstract = {The deep learning advancements have greatly improved the performance of speech recognition systems, and most recent systems are based on the Recurrent Neural Network (RNN). Overall, the RNN works fine with the small sequence data, but suffers from the gradient vanishing problem in case of large sequence. The transformer networks have neutralized this issue and have shown state-of-the-art results on sequential or speech-related data. Generally, in speech recognition, the input audio is converted into an image using Mel-spectrogram to illustrate frequencies and intensities. The image is classified by the machine learning mechanism to generate a classification transcript. However, the audio frequency in the image has low resolution and causing inaccurate predictions. This paper presents a novel end-to-end binary view transformer-based architecture for speech recognition to cope with the frequency resolution problem. Firstly, the input audio signal is transformed into a 2D image using Mel-spectrogram. Secondly, the modified universal transformers utilize the multi-head attention to derive contextual information and derive different speech-related features. Moreover, a feed-forward neural network is also deployed for classification. The proposed system has generated robust results on Google's speech command dataset with an accuracy of 95.16% and with minimal loss. The binary-view transformer eradicates the eventuality of the over-fitting problem by deploying a multi-view mechanism to diversify the input data, and multi-head attention captures multiple contexts from the data's feature map.}
}
@article{SANGOLGI2024547,
title = {Enhancing Cross-Linguistic Image Caption Generation with Indian Multilingual Voice Interfaces using Deep Learning Techniques},
journal = {Procedia Computer Science},
volume = {233},
pages = {547-557},
year = {2024},
note = {5th International Conference on Innovative Data Communication Technologies and Application (ICIDCA 2024)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.03.244},
url = {https://www.sciencedirect.com/science/article/pii/S1877050924006033},
author = {Vijay A Sangolgi and Mithun B Patil and Shubham S Vidap and Satyam S Doijode and Swayam Y Mulmane and Aditya S Vadaje},
keywords = {Multilingual Voice-Based Image Caption Generator (MVBICG), Computer Vision, Natural Language Processing (NLP), Google Translate-Application Programming Interface(API), Deep Learning},
abstract = {The Multilingual Voice-Based Image Caption Generator (MVBICG) is a versatile tool with numerous applications spanning communications, culture preservation, business, and technology, making it indispensable in the interconnected world. The task of image caption generation combines computer vision and NLP (natural language processing) concepts, enabling the system to understand the details or complexities of the image context and describe them in natural language. Image descriptions serve as an invaluable solution for visually impaired individuals. The MVBICG system is designed to provide real-time image descriptions in the form of voice in multiple languages as per user requirements. With the use of an MVBICG, the descriptions can be obtained as a voice output in different languages. Converting a voice into multiple languages with the help of the Google Translate API is often referred to as “multilingual voice conversion” or “multilingual speech synthesis." It leverages the latest advancements in deep learning, particularly convolutional neural networks (CNNs) for image feature extraction and recurrent neural networks (RNNs) with attention mechanisms for natural language generation. In the future, image processing is expected to take center stage as a critical research domain primarily dedicated to the preservation and protection of human lives. The MVBICG demonstrates remarkable performance with BLEU scores of 0.483601 for BLEU-1 and 0.320112 for BLEU-2, indicating its proficiency in generating precise and contextually relevant image captions. These scores further underscore its value in bridging language barriers and enhancing accessibility, highlighting its potential for broader societal impact. Additionally, the system's training progress is illustrated by a loss plot, showing the convergence of the model over time. As image processing continues to advance, the MVBICG emerges as a pivotal research domain, focusing on the preservation and safeguarding of human lives through advanced technologies.}
}
@article{DEEPAK2022107736,
title = {An artificially intelligent approach for automatic speech processing based on triune ontology and adaptive tribonacci deep neural networks},
journal = {Computers & Electrical Engineering},
volume = {98},
pages = {107736},
year = {2022},
issn = {0045-7906},
doi = {https://doi.org/10.1016/j.compeleceng.2022.107736},
url = {https://www.sciencedirect.com/science/article/pii/S0045790622000489},
author = {Gerard Deepak and Deepak Surya and Ishdutt Trivedi and Ayush Kumar and Amrutha Lingampalli and Santhana vijayan},
keywords = {Acoustic model, Automatic speech recognition, Tribonacci deep neural network},
abstract = {Automatic Speech Recognition systems have become essential for an independent automation during the present-day era. A hybrid approach for Automatic Speech Recognition, the TriNNOnto has been proposed in this paper which, integrates different approaches like Language Model integrated with dynamic Triune Ontology generation scheme, Acoustic Model and Feature modelling are hybridised based on the Tribonacci based Deep Neural Network, which decides upon the number of layers depending on the size of the samples and their count. The dynamic generation of Ontologies based on the language models and triune ontology for automatic speech recognition is quite novel. The strategies for feature extraction as and the Tribonacci based deep neural network, based the dynamic adjustment of the number of layers using Tribonacci series contributes towards novelty as well as enhances the performance of speech recognition. The proposed strategy has been evaluated for two datasets and an accuracy of 98.15% and 95.18%, have been achieved for the CMUKids and the TIMIT datasets, respectively with low word error rates.}
}
@article{COBBE2021105573,
title = {Artificial intelligence as a service: Legal responsibilities, liabilities, and policy challenges},
journal = {Computer Law & Security Review},
volume = {42},
pages = {105573},
year = {2021},
issn = {2212-473X},
doi = {https://doi.org/10.1016/j.clsr.2021.105573},
url = {https://www.sciencedirect.com/science/article/pii/S0267364921000467},
author = {Jennifer Cobbe and Jatinder Singh},
keywords = {Cloud computing, Artificial intelligence, Data protection, Intermediary liability, Internet consolidation, Internet regulation},
abstract = {Artificial Intelligence as a Service ('AIaaS') will play a growing role in society's technological infrastructure, enabling, facilitating, and underpinning functionality in many applications. AIaaS providers therefore hold significant power at this infrastructural level. We assess providers’ position in EU law, focusing on assignment of controllership for AIaaS processing chains in data protection law and the availability to providers of protection from liability for customers’ illegal use of AIaaS. We argue that in data protection law, according to current practice, providers are often joint controllers with customers for aspects of the AIaaS processing chain. We further argue that providers lack protection from liability for customers’ illegal activity. More fundamentally, we conclude that the role of providers in customer's application functionality – as well as the significant power asymmetries between providers and customers – challenges traditional understandings of roles and responsibilities in these complex, networked, dynamic processing environments. Finally, we set out some relevant issues for future regulation of AIaaS. In all, AIaaS requires attention from academics, policymakers, and regulators alike.}
}
@article{YAO2025128779,
title = {Imperceptible rhythm backdoor attacks: Exploring rhythm transformation for embedding undetectable vulnerabilities on speech recognition},
journal = {Neurocomputing},
volume = {614},
pages = {128779},
year = {2025},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2024.128779},
url = {https://www.sciencedirect.com/science/article/pii/S0925231224015509},
author = {Wenhan Yao and Jiangkun Yang and Yongqiang He and Jia Liu and Weiping Wen},
keywords = {Backdoor attacks, Speech recognition, Rhythm transformation, Neural vocoder},
abstract = {Speech recognition is an essential start ring of human–computer interaction. Recently, deep learning models have achieved excellent success in this task. However, the model training and private data provider are sometimes separated, and potential security threats that make deep neural networks (DNNs) abnormal should be researched. In recent years, the typical threats, such as backdoor attacks, have been analysed in speech recognition systems. The existing backdoor methods are based on data poisoning. The attacker adds some incorporated changes to benign speech spectrograms or changes the speech components, such as pitch and timbre. As a result, the poisoned data can be detected by human hearing or automatic deep algorithms. To improve the stealthiness of data poisoning, we propose a non-neural and fast algorithm called Random Spectrogram Rhythm Transformation (RSRT) in this paper. The algorithm combines four steps to generate stealthy poisoned utterances. From the perspective of rhythm component transformation, our proposed trigger stretches or squeezes the mel spectrograms and recovers them back to signals. The operation keeps timbre and content unchanged for good stealthiness. Our experiments are conducted on two kinds of speech recognition tasks, including testing the stealthiness of poisoned samples by speaker verification and automatic speech recognition. The results show that our method is effective and stealthy. The rhythm trigger needs a low poisoning rate and gets a very high attack success rate.}
}
@article{LAZZARONI2024108998,
title = {An embedded end-to-end voice assistant},
journal = {Engineering Applications of Artificial Intelligence},
volume = {136},
pages = {108998},
year = {2024},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2024.108998},
url = {https://www.sciencedirect.com/science/article/pii/S0952197624011564},
author = {Luca Lazzaroni and Francesco Bellotti and Riccardo Berta},
keywords = {Voice assistants, Smart vehicles, Edge computing, Embedded systems, Transfer learning, Automatic speech recognition},
abstract = {Voice assistants are spreading in various environments, such as houses and cars, bringing the possibility of controlling heterogeneous Internet of Things devices with simple voice commands. However, massive use of the cloud connection for speech processing requires an efficient and robust Internet connection and raises concerns in terms of privacy. Therefore, we propose an end-to-end solution able to work totally offline, based on a system architecture combining different Deep Learning models to implement all the steps of the speech elaboration process. Being interested in targeting the Italian language, we exploited the transfer learning paradigm, which allows leveraging models trained in English on large datasets and fine-tuning them to the target language on a smaller dataset. The proposed system architecture is configurable and easily extensible to other languages. Experimental results in an automotive application use case show that our solution outperforms the other embedded models and achieves performance comparable to state-of-the-art cloud-connected solutions for Automatic Speech Recognition. Moreover, overall latency is significantly reduced by eliminating the need to connect to the cloud.}
}
@article{GAN2023126623,
title = {Speech emotion recognition via multiple fusion under spatial–temporal parallel network},
journal = {Neurocomputing},
volume = {555},
pages = {126623},
year = {2023},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2023.126623},
url = {https://www.sciencedirect.com/science/article/pii/S0925231223007464},
author = {Chenquan Gan and Kexin Wang and Qingyi Zhu and Yong Xiang and Deepak Kumar Jain and Salvador García},
keywords = {Speech emotion recognition, Speech spectrum, Spatial–temporal parallel network, Multiple fusion},
abstract = {Speech, as a necessary way to express emotions, plays a vital role in human communication. With the continuous deepening of research on emotion recognition in human–computer interaction, speech emotion recognition (SER) has become an essential task to improve the human–computer interaction experience. When performing emotion feature extraction of speech, the method of cutting the speech spectrum will destroy the continuity of speech. Besides, the method of using the cascaded structure without cutting the speech spectrum cannot simultaneously extract speech spectrum information from both temporal and spatial domains. To this end, we propose a spatial–temporal parallel network for speech emotion recognition without cutting the speech spectrum. To further mix the temporal and spatial features, we design a novel fusion method (called multiple fusion) that combines the concatenate fusion and ensemble strategy. Finally, the experimental results on five datasets demonstrate that the proposed method outperforms state-of-the-art methods.}
}
@article{VERMA2024109710,
title = {Neural network developments: A detailed survey from static to dynamic models},
journal = {Computers and Electrical Engineering},
volume = {120},
pages = {109710},
year = {2024},
issn = {0045-7906},
doi = {https://doi.org/10.1016/j.compeleceng.2024.109710},
url = {https://www.sciencedirect.com/science/article/pii/S0045790624006372},
author = {Preeti Raj Verma and Navneet Pratap Singh and Deepika Pantola and Xiaochun Cheng},
keywords = {Dynamic Neural Networks (DNNs), DenseNet, CondenseNet, SkipNet, Dynamic convolutions, Convolutional neural networks(CNN)},
abstract = {Dynamic Neural Networks (DNNs) are an evolving research field within deep learning (DL), offering a robust, adaptable, and efficient alternative to the conventional Static Neural Networks (SNNs). Unlike SNNs, which maintain a fixed architecture of layers, nodes, and connections throughout their operation, DNNs introduce flexibility by allowing modifications to their structure during inference. This adaptability enables DNNs to adjust to the input dynamically, enhancing performance and efficiency. This paper comprehensively analyzes SNNs and DNNs, summarizing their advantages, limitations, and architectures’ impact on network performance and accuracy. In addition, it categorizes SNNs and DNNs, providing a comprehensive analysis of different models such as Multilayer Perceptron (MLP), VGG16, EfficientNet, GoogLeNet, DenseNet, CondenseNet, Dynamic Convolutions, and SkipNet along with their applications in various fields. The paper also delivers an extensive quantitative and qualitative analysis of existing literature in the DNN spectrum, shedding light on the advancements in this field. Furthermore, the computational expenditure in terms of FLOPs, parameters, and model size is minimized in dynamic models, making them more efficient, adaptable, and scalable. The conclusion emphasizes the critical need for ongoing research and innovation in DNNs across multiple disciplines, including Computer Vision, NLP, Robotics, Healthcare, and Weather Forecasting.}
}
@article{CELIK2023107468,
title = {Towards Intelligent-TPACK: An empirical study on teachers’ professional knowledge to ethically integrate artificial intelligence (AI)-based tools into education},
journal = {Computers in Human Behavior},
volume = {138},
pages = {107468},
year = {2023},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2022.107468},
url = {https://www.sciencedirect.com/science/article/pii/S0747563222002886},
author = {Ismail Celik},
keywords = {Artificial intelligence, Teacher education, Technology integration, TPACK},
abstract = {The affordances of artificial intelligence (AI) have not been totally utilized in education. To effectively integrate AI into education, teachers’ AI-specific technological and pedagogical knowledge is important. Furthermore, due to novel ethical issues caused by Al, teachers also must have the knowledge to assess AI-based decisions. None of the previous studies so far explored teacher knowledge to pedagogically and ethically use AI-based tools. Considering this gap, we first developed a scale to measure the knowledge for instructional AI use based on the technological, pedagogical, and content knowledge (TPACK) framework. We extended TPACK with ethical aspects. Secondly, we built a model to investigate the interplay of TPACK components and ethics. The results indicated that as long as teachers have more knowledge to interact with AI-based tools, they will have a better understanding of the pedagogical contributions of AI. Further, technological knowledge (TK) allows teachers to better assess decisions of AI. However, only TK is not sufficient educational integration of AI-based tools. For teachers to deploy AI in education efficiently, TK is meaningful when it is combined with pedagogical knowledge (PK), reflected in technological pedagogical knowledge (TPK). Given pedagogical and technological affordances of AI-based tools, the current study suggests the Intelligent-TPACK framework.}
}
@article{SUNG2022107246,
title = {What drives technology-enhanced storytelling immersion? The role of digital humans},
journal = {Computers in Human Behavior},
volume = {132},
pages = {107246},
year = {2022},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2022.107246},
url = {https://www.sciencedirect.com/science/article/pii/S0747563222000681},
author = {Eunyoung (Christine) Sung and Dai-In {Danny Han} and Sujin Bae and Ohbyung Kwon},
keywords = {Digital human, Storytelling, Augmented reality, Artificial intelligence, Experience economy theory},
abstract = {In this research, we investigate consumer responses to technology-enhanced storytelling marketing via augmented digital humans in two different contexts. We test the role of an augmented digital human stimulus as a moderator for storytelling satisfaction in a technology-enhanced retail complex. Building on visual perception theory and information processing theory, the findings from our study reveal sequential links between the four realms of experience economy theory in a mixed reality environment and subsequent effects on storytelling satisfaction, which in turn are boosted by digital human storytelling. Overall, our findings reveal that digital human storytelling is an effective long-term marketing strategy in technology-enhanced environments.}
}
@article{HAN202389,
title = {A survey of transformer-based multimodal pre-trained modals},
journal = {Neurocomputing},
volume = {515},
pages = {89-106},
year = {2023},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2022.09.136},
url = {https://www.sciencedirect.com/science/article/pii/S0925231222012346},
author = {Xue Han and Yi-Tong Wang and Jun-Lan Feng and Chao Deng and Zhan-Heng Chen and Yu-An Huang and Hui Su and Lun Hu and Peng-Wei Hu},
keywords = {Transformer, Pre-trained model, Multimodal, Documet Layout},
abstract = {With the broad industrialization of Artificial Intelligence(AI), we observe a large fraction of real-world AI applications are multimodal in nature in terms of relevant data and ways of interaction. Pre-trained big models have been proven as the most effective framework for joint modeling of multi-modality data. This paper provides a thorough account of the opportunities and challenges of Transformer-based multimodal pre-trained model (PTM) in various domains. We begin by reviewing the representative tasks of multimodal AI applications, ranging from vision-text and audio-text fusion to more complex tasks such as document layout understanding. We particularly address the new multi-modal research domain of document layout understanding. We further analyze and compare the state-of-the-art Transformer-based multimodal PTMs from multiple aspects, including downstream applications, datasets, input feature embedding, and model architectures. In conclusion, we summarize the key challenges of this field and suggest several future research directions.}
}
@article{DUBRAVOVA2024237,
title = {Artificial Intelligence as an Innovative Element of Support in Policing},
journal = {Procedia Computer Science},
volume = {237},
pages = {237-244},
year = {2024},
note = {International Conference on Industry Sciences and Computer Science Innovation},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.05.101},
url = {https://www.sciencedirect.com/science/article/pii/S1877050924011177},
author = {Hana Dubravova and Jan Cap and Kristyna Holubova and Lukas Hribnak},
keywords = {artificial intelligence, police, GPT, large language model, administrative burden, chat},
abstract = {Currently, the public security sector is faced with an increasing administrative burden that limits the ability of police officers to focus on core security tasks. This paper focuses on the possibility of using large-scale language models (LSMs) as an innovative tool to address this challenge. Based on a careful literature review and analysis of current trends in artificial intelligence, the author team develops a concept for integrating GPTs into police practice, with an emphasis on the potential for reducing administrative burden and supporting efficient processing of relevant information. As part of this research, we have identified key areas of policing where AI could bring significant value, including data analysis and document production assistance. However, it should be emphasized that this technology is still in its early stages of development and its implementation would require a carefully considered approach involving interdisciplinary collaboration and further research to test the theoretical assumptions presented in this study. Thus, this paper contributes to a deeper understanding of the potential benefits and challenges of integrating GPT into policing practice and outlines a path towards future innovative solutions in the field of public safety.}
}
@article{LI2023111818,
title = {A speech-enabled virtual assistant for efficient human–robot interaction in industrial environments},
journal = {Journal of Systems and Software},
volume = {205},
pages = {111818},
year = {2023},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2023.111818},
url = {https://www.sciencedirect.com/science/article/pii/S0164121223002133},
author = {Chen Li and Dimitris Chrysostomou and Hongji Yang},
keywords = {Human–robot interaction, Natural language processing, Interactive systems, Client–server systems},
abstract = {This paper presents a natural language-enabled virtual assistant (VA), named Max, developed to support flexible and scalable human–robot interactions (HRI) with industrial robots. Regardless of the numerous natural language interfaces already proposed for intuitive HRI on the industrial shop floor, most of those interfaces remain tightly bound with a specific robotic system. Besides, the lack of a natural and efficient human–robot communication protocol hinders the user experience. Therefore three key elements characterize the proposed framework. First, a Client–Server style architecture is introduced so Max can provide a centralized solution for managing and controlling various types of robots deployed on the shop floor. Second, inspired by human–human communication, two conversation strategies, lexical-semantic and general diversion strategies, are used to guide Max’s response generation. These conversation strategies were embedded to improve the operator’s engagement with the manufacturing tasks. Third, we fine-tuned the state-of-the-art (SOTA) pre-trained model, Bidirectional Encoder Representations from Transformers (BERT), to support a highly accurate prediction of requested intents from the operator and robot services. Multiple experiments were conducted using the latest iteration of our autonomous industrial mobile manipulator, “Little Helper (LH)”, to validate Max’s performance in a real manufacturing environment.}
}
@article{JAFARZADEH2021103536,
title = {A wearable sensor vest for social humanoid robots with GPGPU, IoT, and modular software architecture},
journal = {Robotics and Autonomous Systems},
volume = {139},
pages = {103536},
year = {2021},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2020.103536},
url = {https://www.sciencedirect.com/science/article/pii/S0921889019306323},
author = {Mohsen Jafarzadeh and Stephen Brooks and Shimeng Yu and Balakrishnan Prabhakaran and Yonas Tadesse},
keywords = {Social robot, Internet of Things, GPGPU, Human–robot interaction, Software architecture, Senor vest},
abstract = {Currently, most social robots interact with their surroundings and humans through sensors that are integral parts of the robots, which limits the usability of the sensors, human–robot interaction, and interchangeability. A wearable sensor garment that fits many robots is needed in many applications. This article presents an affordable wearable sensor vest, and an open-source software architecture with the Internet of Things (IoT) for social humanoid robots. The vest consists of touch, temperature, gesture, distance, vision sensors, and a wireless communication module. The IoT feature allows the robot to interact with humans locally and over the Internet. The designed architecture works for any social robot that has a general-purpose graphics processing unit (GPGPU), I2C/SPI buses, Internet connection, and the Robotics Operating System (ROS). The modular design of this architecture enables developers to easily add/remove/update complex behaviors. The proposed software architecture provides IoT technology, GPGPU nodes, I2C and SPI bus mangers, audio-visual interaction nodes (speech to text, text to speech, and image understanding), and isolation between behavior nodes and other nodes. The proposed IoT solution consists of related nodes in the robot, a RESTful web service, and user interfaces. We used the HTTP protocol as a means of two-way communication with the social robot over the Internet. Developers can easily edit or add nodes in C, C++, and Python programming languages. Our architecture can be used for designing more sophisticated behaviors for social humanoid robots.}
}
@article{BELLO2025100031,
title = {Cloud computing for chatbot in the construction industry: An implementation framework for conversational-BIM voice assistant},
journal = {Digital Engineering},
volume = {5},
pages = {100031},
year = {2025},
issn = {2950-550X},
doi = {https://doi.org/10.1016/j.dte.2024.100031},
url = {https://www.sciencedirect.com/science/article/pii/S2950550X24000311},
author = {Sururah A. Bello and Lukumon O. Oyedele and Lukman A. Akanbi and Abdul-Lateef Bello},
keywords = {Software project management, Amazon web services, Cloud computing, Building information modelling (BIM), Conversational AI, Construction industry, Framework implementation, Chatbot, construction workers, Design thinking methodology, Focus group, Stakeholders management},
abstract = {This study presents a structural framework for selecting cloud services for the Conversational AI system implementation in the construction industry using Design Thinking Methodology. A focus group discussion approach was used to obtain user requirements from construction workers to implement the Conversational AI for BIM. This resulted in five factors: finance, speed of operation, privacy, estimation, and interface. The user specifications were mapped into technical modules, which were used to select cloud services employed to implement the virtual assistant for the construction industry. The study thus presented the comprehensive requirements for the different categories of construction workers to implement the Conversational-BIM Chatbot (Conversational-BIM) system. Furthermore, the study presented the architecture of Conversational-BIM using Amazon Web Services. The study is useful to researchers and IT developers in implementing chatbots for the construction industry as it presents the relevant considerations for conversational AI applications in the industry.}
}
@article{TRABELSI20222242,
title = {Evaluation of the efficiency of state-of-the-art Speech Recognition engines},
journal = {Procedia Computer Science},
volume = {207},
pages = {2242-2252},
year = {2022},
note = {Knowledge-Based and Intelligent Information & Engineering Systems: Proceedings of the 26th International Conference KES2022},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2022.09.534},
url = {https://www.sciencedirect.com/science/article/pii/S1877050922014338},
author = {Asma Trabelsi and Sébastien Warichet and Yassine Aajaoun and Séverine Soussilane},
keywords = {Speech Recognition, ASR, Data Sovereignty, Kaldi, DeepSpeech},
abstract = {Speech Recognition is one of the several Artificial Intelligence applications. It helps us converting spoken words into text. It can be part of various daily use cases in order to deal with accessibility. Google Assistant and Amazon's Alexa are in the top of list of the well-known Speech Recognition tools. European companies cannot use these solutions as they should guarantee data sovereignty. Another important point is that these mentioned solutions are not customized. So that, it is not possible to deal with new accents or new vocabularies. To cope with these problems, one can either use European Automatic Speech Recognition (ASR) solutions or build his own personalized models using well-known open-source tools like Deep Speech or Kaldi. Choosing the best solution between both, Kaldi and DeepSpeech, is an important task. The criteria for judging the finest method are the Accuracy and the Inference Time. In this paper, we make theoretical and experimental study between DeepSpeech and Kaldi. Also, Vosk and LinTO, open-source solutions build in top of Kaldi, will be included in the comparison study.}
}
@article{MOHAMMEDQASEM2022107971,
title = {Real-time data of COVID-19 detection with IoT sensor tracking using artificial neural network},
journal = {Computers and Electrical Engineering},
volume = {100},
pages = {107971},
year = {2022},
issn = {0045-7906},
doi = {https://doi.org/10.1016/j.compeleceng.2022.107971},
url = {https://www.sciencedirect.com/science/article/pii/S0045790622002464},
author = {Roa'a Mohammedqasem and Hayder Mohammedqasim and Oguz Ata},
keywords = {COVID-19, Synthetic minority oversampling technique, Recursive feature elimination, Imbalanced Dataset, Internet of Things},
abstract = {The coronavirus pandemic has affected people all over the world and posed a great challenge to international health systems. To aid early detection of coronavirus disease-2019 (COVID-19), this study proposes a real-time detection system based on the Internet of Things framework. The system collects real-time data from users to determine potential coronavirus cases, analyses treatment responses for people who have been treated, and accurately collects and analyses the datasets. Artificial intelligence-based algorithms are an alternative decision-making solution to extract valuable information from clinical data. This study develops a deep learning optimisation system that can work with imbalanced datasets to improve the classification of patients. A synthetic minority oversampling technique is applied to solve the problem of imbalance, and a recursive feature elimination algorithm is used to determine the most effective features. After data balance and extraction of features, the data are split into training and testing sets for validating all models. The experimental predictive results indicate good stability and compatibility of the models with the data, providing maximum accuracy of 98% and precision of 97%. Finally, the developed models are demonstrated to handle data bias and achieve high classification accuracy for patients with COVID-19. The findings of this study may be useful for healthcare organisations to properly prioritise assets.}
}
@article{CHO2022,
title = {Effect of Applying a Real-Time Medical Record Input Assistance System With Voice Artificial Intelligence on Triage Task Performance in the Emergency Department: Prospective Interventional Study},
journal = {JMIR Medical Informatics},
volume = {10},
number = {8},
year = {2022},
issn = {2291-9694},
doi = {https://doi.org/10.2196/39892},
url = {https://www.sciencedirect.com/science/article/pii/S2291969422002186},
author = {Ara Cho and In Kyung Min and Seungkyun Hong and Hyun Soo Chung and Hyun Sim Lee and Ji Hoon Kim},
keywords = {voice recognition, artificial intelligence, natural language processing, emergency department, triage},
abstract = {Background
Natural language processing has been established as an important tool when using unstructured text data; however, most studies in the medical field have been limited to a retrospective analysis of text entered manually by humans. Little research has focused on applying natural language processing to the conversion of raw voice data generated in the clinical field into text using speech-to-text algorithms.
Objective
In this study, we investigated the promptness and reliability of a real-time medical record input assistance system with voice artificial intelligence (RMIS-AI) and compared it to the manual method for triage tasks in the emergency department.
Methods
From June 4, 2021, to September 12, 2021, RMIS-AI, using a machine learning engine trained with 1717 triage cases over 6 months, was prospectively applied in clinical practice in a triage unit. We analyzed a total of 1063 triage tasks performed by 19 triage nurses who agreed to participate. The primary outcome was the time for participants to perform the triage task.
Results
The median time for participants to perform the triage task was 204 (IQR 155, 277) seconds by RMIS-AI and 231 (IQR 180, 313) seconds using manual method; this difference was statistically significant (P<.001). Most variables required for entry in the triage note showed a higher record completion rate by the manual method, but in the recording of additional chief concerns and past medical history, RMIS-AI showed a higher record completion rate than the manual method. Categorical variables entered by RMIS-AI showed less accuracy compared with continuous variables, such as vital signs.
Conclusions
RMIS-AI improves the promptness in performing triage tasks as compared to using the manual input method. However, to make it a reliable alternative to the conventional method, technical supplementation and additional research should be pursued.}
}
@article{BIRD2024112293,
title = {Customer service chatbot enhancement with attention-based transfer learning},
journal = {Knowledge-Based Systems},
volume = {301},
pages = {112293},
year = {2024},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2024.112293},
url = {https://www.sciencedirect.com/science/article/pii/S0950705124009274},
author = {Jordan J. Bird and Ahmad Lotfi},
keywords = {Chatbot, Customer service robotics, Social robotics, Human–robot interaction, Natural language processing},
abstract = {Customer service is an important and expensive aspect of business, often being the largest department in most companies. With growing societal acceptance and increasing cost efficiency due to mass production, service robots are beginning to cross from the industrial domain to the social domain. Currently, customer service robots tend to be digital and emulate social interactions through on-screen text, but state-of-the-art research points towards physical robots soon providing customer service in person. This article explores the feasibility of Transfer Learning different customer service domains to improve chatbot models. In our proposed approach, transfer learning-based chatbot models are initially assigned to learn one domain from an initial random weight distribution. Each model is then tasked with learning another domain by transferring knowledge from the previous domains. To evaluate our approach, a range of 19 companies from domains such as e-Commerce, telecommunications, and technology are selected through social interaction with X (formerly Twitter) customer support accounts. The results show that the majority of models are improved when transferring knowledge from at least one other domain, particularly those more data-scarce than others. General language transfer learning is observed, as well as higher-level transfer of similar domain knowledge. For each of the 19 domains, the Wilcoxon signed-rank test suggests that 16 have statistically significant distributions between transfer and non-transfer learning. Finally, feasibility is explored for the deployment of chatbot models to physical robot platforms including “Pepper”, a semi-humanoid robot manufactured by SoftBank Robotics, and “Temi”, a personal assistant robot.}
}
@article{MATEI20221164,
title = {Safety Navigation using a Conversational User Interface For Visually Impaired People},
journal = {Procedia Computer Science},
volume = {207},
pages = {1164-1173},
year = {2022},
note = {Knowledge-Based and Intelligent Information & Engineering Systems: Proceedings of the 26th International Conference KES2022},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2022.09.172},
url = {https://www.sciencedirect.com/science/article/pii/S1877050922010547},
author = {Madalin Matei and Lenuta Alboaie and Adrian Iftene},
keywords = {visually impaired people, EOA, conversational user interface, human interaction},
abstract = {Starting with everyday activities such as taking a walk at the outside environments, use of different public transportation methods or even buying different goods, visually impaired people need to put in a considerable effort to complete these so-called trivial tasks for sighted people. Given this, according to WHO (World Health Organization) it is estimated that there are at least 2.2 billion people who have a near or distance vision impairment. This paper presents an ongoing project that aims to address mainly two problems: the creation of a system designed to safely moving visually impaired people to points of interest using public transportation and designing of a communication mechanism that will balance between keeping the individual as safe as possible and also providing relevant indications. The current paper is divided in two main parts. In the first part, in addition to the study of similar systems, the factors underlying the architectural decisions on which the developed system was built, are debated and analysed. The second part presents the results obtained after a series of preliminary tests carried out with the help of visually impaired people. The application seems promising, being enthusiastically received by those who tested it, because it offers them safety and independence when travelling through the city.}
}
@article{JIANG2025101117,
title = {Neuron signal attenuation activation mechanism for deep learning},
journal = {Patterns},
volume = {6},
number = {1},
pages = {101117},
year = {2025},
issn = {2666-3899},
doi = {https://doi.org/10.1016/j.patter.2024.101117},
url = {https://www.sciencedirect.com/science/article/pii/S2666389924002897},
author = {Wentao Jiang and Heng Yuan and Wanjun Liu},
keywords = {generalized linear system, neuron signal activation, attenuation-activation function, deep learning, neural network},
abstract = {Summary
Neuron signal activation is at the core of deep learning and broadly impacts science and engineering. Despite growing interest in neuron cell stimulation via amplitude current, the activation mechanism of biological neurons has limited application in deep learning due to the lack of a universal mathematical principle suitable for artificial neural networks. Here, we show how deep learning can go beyond the current learning effects through a newly proposed neuron signal activation mechanism. To achieve this, we report a new cross-disciplinary method for neuron signal attenuation, using the inference of differential equations within generalized linear systems to enhance the efficiency of deep learning. We formulate the mathematical model of the efficient activation function, which we refer to as Attenuation (Ant). Ant can represent higher-order derivatives and stabilize data distributions in deep-learning tasks. We demonstrate the effectiveness, stability, and generalization of Ant on many challenging tasks across various neural network architectures.}
}
@article{OUADDI2024293,
title = {Architecture, Tools, and DSLs for Developing Conversational Agents: An Overview},
journal = {Procedia Computer Science},
volume = {231},
pages = {293-298},
year = {2024},
note = {14th International Conference on Emerging Ubiquitous Systems and Pervasive Networks / 13th International Conference on Current and Future Trends of Information and Communication Technologies in Healthcare (EUSPN/ICTH 2023)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2023.12.206},
url = {https://www.sciencedirect.com/science/article/pii/S1877050923022184},
author = {Charaf Ouaddi and Lamya Benaddi and Abdeslam Jakimi},
keywords = {Conversational agent, Chatbot, framework, platform, Architecture, domain-specific language},
abstract = {Conversational agents (CA) are software programs that can converse with users using natural language. They are now widely used in various domains, such as tourism, healthcare, and others, to perform tasks and provide permanent assistance to users by interacting with them in natural language. The development of such applications is a task that requires expertise in several fields, such as software engineering, machine learning, deep learning, and natural language processing (NLP). However, several platforms and frameworks on the market facilitate the building of CA, such as Dialogflow, Rasa, and others. Recently, several research studies have proposed solutions to reduce the workload of developers and designers by offering their model-driven development approaches using domain-specific languages (DSLs), which facilitate the automation of the development of CA. This work aims to provide an Overview of CA to identify and describe their architecture and the details of its key components. and discuss the tools and technologies for their development. At the same time, discover the research topics that focus on using DSLs for model-driven development to automate and speed up the creation of these agents and discover approaches and technologies employed to implement each of these DSLs.}
}
@article{AKDENIZ2021100347,
title = {Maya: An artificial intelligence based smart toy for pre-school children},
journal = {International Journal of Child-Computer Interaction},
volume = {29},
pages = {100347},
year = {2021},
issn = {2212-8689},
doi = {https://doi.org/10.1016/j.ijcci.2021.100347},
url = {https://www.sciencedirect.com/science/article/pii/S221286892100060X},
author = {Mevlüde Akdeniz and Fatih Özdinç},
keywords = {Smart toys, Artificial intelligence, Concept teaching, Pre-school children, Educational robots},
abstract = {Toys are valuable educational tools that, while entertaining, they also help in childhood development. Traditional instructional materials do not adequately take into account children’s individual development abilities. New instructional materials should be developed so that children can obtain education in accordance with their own learning pace and learning processes. The possible benefits to be drawn from smart devices that cater to more than one sensory organ simultaneously and the inferences to be drawn from scenarios utilizing such instructional materials are amazing. The aim of this study was to develop a smart toy using artificial intelligence in order to support the concept development of preschool children in terms of numbers, shapes, animals and colors. In this study, the design and development process of the smart toy Maya is explained. Maya is a humanoid robot that supports children in learning at their own pace and can determine what and how to teach and to which child. It is an intelligent tutoring system that can perform image processing and natural language processing in the teaching process. Maya is being able to recognize its user, to interact, and to manage learning activities according to the learning speed of the child. A design-based research method was used in the study. A needs analysis was conducted during the design phase of the smart toy, and the attributes that a toy should provide to help the acquisition of the concept by children were determined. A toy prototype was developed within the framework of the determined criteria. Preschool teachers were interviewed about the prototype toy. Improvements were made to the toy in response to its perceived flaws as well as other feedback, and the second iteration of the smart toy was developed. The toy’s shortcomings were discovered through interviews and were then removed, and the toy was given its final form. An interactive smart toy which can be used for both individual and group activities was developed at the end of research. In this study, the educational, hardware and software components of the smart toy are emphasized, and a framework for the smart toy design and the development process is provided.}
}
@article{FU2025105347,
title = {Generative AI in the context of assistive technologies: Trends, limitations and future directions},
journal = {Image and Vision Computing},
volume = {154},
pages = {105347},
year = {2025},
issn = {0262-8856},
doi = {https://doi.org/10.1016/j.imavis.2024.105347},
url = {https://www.sciencedirect.com/science/article/pii/S0262885624004529},
author = {Biying Fu and Abdenour Hadid and Naser Damer},
keywords = {Assistive AI, Generative AI, Generative models, Assistive systems, Assistive technologies and services},
abstract = {With the tremendous successes of Large Language Models (LLMs) like ChatGPT for text generation and Dall-E for high-quality image generation, generative Artificial Intelligence (AI) models have shown a hype in our society. Generative AI seamlessly delved into different aspects of society ranging from economy, education, legislation, computer science, finance, and even healthcare. This article provides a comprehensive survey on the increased and promising use of generative AI in assistive technologies benefiting different parties, ranging from the assistive system developers, medical practitioners, care workforce, to the people who need the care and the comfort. Ethical concerns, biases, lack of transparency, insufficient explainability, and limited trustworthiness are major challenges when using generative AI in assistive technologies, particularly in systems that impact people directly. Key future research directions to address these issues include creating standardized rules, establishing commonly accepted evaluation metrics and benchmarks for explainability and reasoning processes, and making further advancements in understanding and reducing bias and its potential harms. Beyond showing the current trends of applying generative AI in the scope of assistive technologies in four identified key domains, which include care sectors, medical sectors, helping people in need, and co-working, the survey also discusses the current limitations and provides promising future research directions to foster better integration of generative AI in assistive technologies.}
}
@article{BISOGNI2024104145,
title = {Acoustic features analysis for explainable machine learning-based audio spoofing detection},
journal = {Computer Vision and Image Understanding},
volume = {249},
pages = {104145},
year = {2024},
issn = {1077-3142},
doi = {https://doi.org/10.1016/j.cviu.2024.104145},
url = {https://www.sciencedirect.com/science/article/pii/S1077314224002261},
author = {Carmen Bisogni and Vincenzo Loia and Michele Nappi and Chiara Pero},
keywords = {Deepfake audio, Deepfake detection, Audio spoofing, Explainable AI, Acoustic features},
abstract = {The rapid evolution of synthetic voice generation and audio manipulation technologies poses significant challenges, raising societal and security concerns due to the risks of impersonation and the proliferation of audio deepfakes. This study introduces a lightweight machine learning (ML)-based framework designed to effectively distinguish between genuine and spoofed audio recordings. Departing from conventional deep learning (DL) approaches, which mainly rely on image-based spectrogram features or learning-based audio features, the proposed method utilizes a diverse set of hand-crafted audio features – such as spectral, temporal, chroma, and frequency-domain features – to enhance the accuracy of deepfake audio content detection. Through extensive evaluation and experiments on three well-known datasets, ASVSpoof2019, FakeAVCelebV2, and an In-The-Wild database, the proposed solution demonstrates robust performance and a high degree of generalization compared to state-of-the-art methods. In particular, our method achieved 89% accuracy on ASVSpoof2019, 94.5% on FakeAVCelebV2, and 94.67% on the In-The-Wild database. Additionally, the experiments performed on explainability techniques clarify the decision-making processes within ML models, enhancing transparency and identifying crucial features essential for audio deepfake detection.}
}
@article{GONG2023107268,
title = {A survey on dataset quality in machine learning},
journal = {Information and Software Technology},
volume = {162},
pages = {107268},
year = {2023},
issn = {0950-5849},
doi = {https://doi.org/10.1016/j.infsof.2023.107268},
url = {https://www.sciencedirect.com/science/article/pii/S0950584923001222},
author = {Youdi Gong and Guangzhen Liu and Yunzhi Xue and Rui Li and Lingzhong Meng},
keywords = {Dataset, Dataset quality, Machine Learning},
abstract = {With the rise of big data, the quality of datasets has become a crucial factor affecting the performance of machine learning models. High-quality datasets are essential for the realization of data value. This survey article summarizes the research direction of dataset quality in machine learning, including the definition of related concepts, analysis of quality issues and risks, and a review of dataset quality dimensions and metrics throughout the dataset lifecycle and a review of dataset quality metrics analyzed from a dataset lifecycle perspective and summarized in literatures. Furthermore, this article introduces a comprehensive quality evaluation process, which includes a framework for dataset quality evaluation with dimensions and metrics, computation methods for quality metrics, and assessment models. These studies provide valuable guidance for evaluating dataset quality in the field of machine learning, which can help improve the accuracy, efficiency, and generalization ability of machine learning models, and promote the development and application of artificial intelligence technology.}
}
@article{SINTHUJA2024789,
title = {Extraction of Text from Images Using Deep Learning},
journal = {Procedia Computer Science},
volume = {235},
pages = {789-798},
year = {2024},
note = {International Conference on Machine Learning and Data Engineering (ICMLDE 2023)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.04.075},
url = {https://www.sciencedirect.com/science/article/pii/S1877050924007518},
author = {M Sinthuja and Chirag Ganesh Padubidri and Gaddam Sai Jayachandra and Mudduluru Charan Teja and Golthi Sai Pavan Kumar},
keywords = {Deep Learning, OCR, Text Recognition Convolutional Neural Networks, Bi-directional LSTM},
abstract = {In the recent scenario, it is important to extract the text from various formats, including handwritten and documents. The ability to accurately detect and recognize text, is a crucial task in many fields, such as OCR systems, document analysis, and image processing. Convolutional neural networks (CNN) and bidirectional long short-term memory (BiLSTM) are used in a unique method for text detection. Additionally, CNN consist of six sequential layers by using Adam optimizer and SoftMax. The proposed approach is designed effectively to handle the variability and complexity of text in both handwritten and document formats. The proposed approach achieved a significant improvement in text detection and recognition accuracy, with 88.5 percentage while comparing with the existing techniques of CNN and LSTM which has an accuracy of 81.8 percentage.}
}
@article{SONG2024100069,
title = {Developing an immersive game-based learning platform with generative artificial intelligence and virtual reality technologies – “LearningverseVR”},
journal = {Computers & Education: X Reality},
volume = {4},
pages = {100069},
year = {2024},
issn = {2949-6780},
doi = {https://doi.org/10.1016/j.cexr.2024.100069},
url = {https://www.sciencedirect.com/science/article/pii/S2949678024000199},
author = {Yanjie Song and Kaiyi Wu and Jiaoyang Ding},
keywords = {Generative AI, Virtual reality (VR), Game-based learning, Immersion, Interaction},
abstract = {The rapid evolution of generative artificial intelligence (AI) and virtual reality (VR) technologies are revolutionising various fields, including education and gaming industries. However, studies on how to enhance immersive game-based learning with AI and VR technologies remain scant. Given this, the article presents the creation of “LearningverseVR,” an immersive game-based learning platform developed using generative AI and VR technologies, which is based on “Learningverse,” a metaverse platform developed by the lead author and her research team. The “LearningverseVR” platform uses Unity as the client and Python, Flask and MySQL as the backend. Unity's multiplayer service provides multiplayer online functionality, supporting learners to engage in immersive and interactive learning activities. The design framework of the platform consists of two main components: Game-based learning with generative AI and immersion with VR technologies. First, generative AI is used to create NPCs with diverse personalities and life backgrounds, and enable learners to interact with NPCs without scripted dialogues, creating an interactive and immersive game-based learning environment. Secondly, such a learning experience is enhanced by leveraging the Large Language Model (LLM) ecosystem with VR technology. The creation of the “LearningverseVR” platform provides novel perspectives on digital game-based learning.}
}
@article{HAN2021225,
title = {Pre-trained models: Past, present and future},
journal = {AI Open},
volume = {2},
pages = {225-250},
year = {2021},
issn = {2666-6510},
doi = {https://doi.org/10.1016/j.aiopen.2021.08.002},
url = {https://www.sciencedirect.com/science/article/pii/S2666651021000231},
author = {Xu Han and Zhengyan Zhang and Ning Ding and Yuxian Gu and Xiao Liu and Yuqi Huo and Jiezhong Qiu and Yuan Yao and Ao Zhang and Liang Zhang and Wentao Han and Minlie Huang and Qin Jin and Yanyan Lan and Yang Liu and Zhiyuan Liu and Zhiwu Lu and Xipeng Qiu and Ruihua Song and Jie Tang and Ji-Rong Wen and Jinhui Yuan and Wayne Xin Zhao and Jun Zhu},
keywords = {Pre-trained models, Language models, Transfer learning, Self-supervised learning, Natural language processing, Multimodal processing, Artificial intelligence},
abstract = {Large-scale pre-trained models (PTMs) such as BERT and GPT have recently achieved great success and become a milestone in the field of artificial intelligence (AI). Owing to sophisticated pre-training objectives and huge model parameters, large-scale PTMs can effectively capture knowledge from massive labeled and unlabeled data. By storing knowledge into huge parameters and fine-tuning on specific tasks, the rich knowledge implicitly encoded in huge parameters can benefit a variety of downstream tasks, which has been extensively demonstrated via experimental verification and empirical analysis. It is now the consensus of the AI community to adopt PTMs as backbone for downstream tasks rather than learning models from scratch. In this paper, we take a deep look into the history of pre-training, especially its special relation with transfer learning and self-supervised learning, to reveal the crucial position of PTMs in the AI development spectrum. Further, we comprehensively review the latest breakthroughs of PTMs. These breakthroughs are driven by the surge of computational power and the increasing availability of data, towards four important directions: designing effective architectures, utilizing rich contexts, improving computational efficiency, and conducting interpretation and theoretical analysis. Finally, we discuss a series of open problems and research directions of PTMs, and hope our view can inspire and advance the future study of PTMs.}
}
@article{HOSSAIN2025100388,
title = {Towards walkable footpath detection for the visually impaired on Bangladeshi roads with smartphones using deep edge intelligence},
journal = {Array},
volume = {26},
pages = {100388},
year = {2025},
issn = {2590-0056},
doi = {https://doi.org/10.1016/j.array.2025.100388},
url = {https://www.sciencedirect.com/science/article/pii/S2590005625000153},
author = {Md. Ishan Arefin Hossain and Jareen Anjom and Rashik Iram Chowdhury},
keywords = {Walkable footpath, Image segmentation, Edge intelligence, Deep learning, Computer vision},
abstract = {One of the ongoing prevalent issues is the challenge faced by visually impaired people when crossing footpaths, especially in a densely populated geographic location such as Dhaka city in Bangladesh, where numerous accidents take place that primarily result in the demise of the affected individuals. Visually impaired people find themselves in precarious situations while navigating through these footpaths. So, having an accessible edge device like a smartphone capable of predicting walkable footpaths by detecting obstacles in real-time is a blessing. However, little work has been done on efficient obstacle detection on footpaths and their corresponding distance prediction in real-time. To address this burning issue, a U-Net-based lightweight deep learning model called QPULM along with an obstacle distance measurement technique called SODD have been proposed in this research, which is utilized in an Android application to detect walkable footpath by avoiding the obstacles via the image captured and to broadcast the directions of the walkable paths using audio feedback. The proposed novel lightweight model at the Edge showed an excellent accuracy of 99.37% with a faster prediction time in milliseconds in real-time, which is significantly better and more efficient than the existing related solutions.}
}